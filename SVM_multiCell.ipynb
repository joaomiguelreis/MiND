{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are some experiments with SVM. Here I test the 3 main SVC (Support Vector Classification) algorithms: Linear SVM, Nu-SVM and C-SVM. The N-SVM seems to be the best but we need more experiments.\n",
    "\n",
    "This analysis is very simple. I shuffle my dataset and take $30\\%$ of testing. I do this $M$ times and store each shuffled data set. Then I preform $M$ classifications and take the mean of thhe numer of miss-classified samples and corresponding variance.\n",
    "\n",
    "This is only for a single cell (like Anabel did). I guess we should have to repeat this for all cells in the mesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import display, Math #\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup pandas options\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:.5f}'.format\n",
    "\n",
    "# Setup numpy options\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "# Get the data\n",
    "# PT_data = pd.read_excel(\"PTResults_trimmed.xlsx\")\n",
    "PT_data = pd.read_excel(\"PTResults.xlsx\")\n",
    "# PT_data = pd.read_excel(\"../../Data/PTResults_ice.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can change the number of shuffles and test size. This will store the training and testing features and targets to be used for any algorithms you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAINING SVM  ##\n",
    "\n",
    "\n",
    "M = 1000 # number of shuffles\n",
    "test_size = 15 # number of cells to be tested out of 100\n",
    "\n",
    "\n",
    "\n",
    "data_matrix = np.asarray(PT_data)\n",
    "X_aux = data_matrix[:,0:5]\n",
    "X = []\n",
    "y = []\n",
    "n_loc = len(data_matrix[0,5:-1])\n",
    "for i in range(5):\n",
    "    for loc in range(7,n_loc):\n",
    "        x = np.append(X_aux[i,:], loc-5)\n",
    "        X.append(x)\n",
    "        y.append(data_matrix[i,loc-5].astype(int))\n",
    "\n",
    "training_features_vector = []\n",
    "testing_features_vector = []\n",
    "training_target_vector = []\n",
    "testing_target_vector = []\n",
    "\n",
    "\n",
    "\n",
    "#Splitting the data into training and testing and storing to reuze same seeds\n",
    "# for the different algorithms\n",
    "for i in range(M):\n",
    "    \n",
    "    #Splitting the data into training and testing\n",
    "    training_features, testing_features, training_target, testing_target = train_test_split(\n",
    "        X, y, test_size=test_size/100, shuffle=True)\n",
    "\n",
    "    #store\n",
    "    training_features_vector.append(training_features)\n",
    "    testing_features_vector.append(testing_features)\n",
    "    training_target_vector.append(training_target)\n",
    "    testing_target_vector.append(testing_target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This uses the kernel $K(x,x') := \\langle x, x'\\rangle$. It's here just for fun. It gives very bad results..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of miss classified cells out of 1000 shuffles: 5.8930952381 +- 0.198391887731\n"
     ]
    }
   ],
   "source": [
    "# Linear Support Vector Classification\n",
    "MSE_linear = 0\n",
    "VarMSE_linear = 0\n",
    "missclass = []\n",
    "for i in range(M):\n",
    "    training_features = training_features_vector[i]\n",
    "    testing_features = testing_features_vector[i]\n",
    "    training_target = training_target_vector[i]\n",
    "    testing_target = testing_target_vector[i]\n",
    "    #Training with Linear SVC\n",
    "    model = LinearSVC(random_state=0, tol=1e-5)\n",
    "    model.fit(training_features, training_target)\n",
    "\n",
    "    #Comparing prediction with testing values\n",
    "    prediction = model.predict(testing_features)\n",
    "    \n",
    "    #Get means and std\n",
    "    MSE = mean_squared_error(prediction, testing_target)\n",
    "    MSE_linear += MSE\n",
    "    VarMSE_linear += MSE*MSE\n",
    "    missclass.append(test_size*mean_squared_error(prediction, testing_target))\n",
    "    \n",
    "MSE_linear /= M\n",
    "VarMSE_linear -= M*MSE_linear**2\n",
    "VarMSE_linear /=(M-1)\n",
    "count_linear = test_size*MSE_linear\n",
    "countstd_linear = test_size*VarMSE_linear\n",
    "print('Average number of miss classified cells out of ' + str(M) + ' shuffles: ' + \n",
    "      str(count_linear) + ' +- ' + str(countstd_linear))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nu-Support Vector Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See documentation: https://scikit-learn.org/stable/modules/generated/sklearn.svm.NuSVC.html\n",
    "\n",
    "We start by choosing the kernel: 'rbf' or 'poly'. \n",
    "    - If 'rbf' is choosen then we can choose two parameters: $\\nu$ and $\\gamma$\n",
    "    - If 'poly' or 'sigmoid' is choosen then we can choose three parameters: $\\nu$, $\\gamma$ and polynomial degree\n",
    "\n",
    "The values of the parameters to be tested are in: nu_vector, gamma_vector and degree_vector. You may change these values if you want. Be carefull, for dregree > 3 things become slow for $\\gamma > 0.01$.\n",
    "\n",
    "The strategy to find to optimum is to save all combinations of parameters that give $<15\\%$ misclassification with variance $<5\\%$. To do so we start with kernel = 'rbf' to tune the gamma values. We will see that the kernel = 'poly' is the best. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier function\n",
    "\n",
    "This is our personalised classifier that returns the mean squared error, the variance of the MSE and the number of misclassified shuffles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nu-Support Vector Classification\n",
    "def mySVC_Nu(nu, kernel, gamma, degree=0):\n",
    "\n",
    "    MSE_Nu = 0\n",
    "    VarMSE_Nu = 0\n",
    "    missclass = []\n",
    "    for i in range(M):\n",
    "        \n",
    "        training_features = training_features_vector[i]\n",
    "        testing_features = testing_features_vector[i]\n",
    "        training_target = training_target_vector[i]\n",
    "        testing_target = testing_target_vector[i]\n",
    "\n",
    "        #Training with Nu-SVC\n",
    "        model = NuSVC(nu = nu, kernel = kernel, degree=degree, gamma=gamma)\n",
    "            \n",
    "        model.fit(training_features, training_target)\n",
    "\n",
    "        #Comparing prediction with testing values\n",
    "        prediction = model.predict(testing_features)\n",
    "\n",
    "        #Get means and std\n",
    "        MSE = mean_squared_error(prediction, testing_target)\n",
    "        MSE_Nu += MSE\n",
    "        VarMSE_Nu += MSE*MSE\n",
    "        missclass.append(test_size*mean_squared_error(prediction, testing_target))\n",
    "\n",
    "    MSE_Nu /= M\n",
    "    VarMSE_Nu -= M*MSE_Nu**2\n",
    "    VarMSE_Nu /=(M-1)\n",
    "#     count_Nu = test_size*MSE_Nu\n",
    "#     countVar_Nu = test_size*VarMSE_Nu\n",
    "           \n",
    "    return MSE_Nu, VarMSE_Nu, missclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kernel = 'rbf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# simulations done 10/28\n",
      "# simulations done 20/28\n",
      "candidate indices for optimal distributions\n",
      "[[0, 0], [0, 1], [0, 2], [0, 3], [1, 0], [1, 1], [1, 2], [1, 3], [2, 0], [2, 1], [2, 2], [2, 3], [3, 0], [3, 1], [3, 2], [3, 3], [4, 0], [4, 1], [4, 2], [4, 3], [5, 0], [5, 1], [5, 2], [5, 3], [6, 0], [6, 1], [6, 2], [6, 3]]\n"
     ]
    }
   ],
   "source": [
    "nu_vector = [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]\n",
    "gamma_vector = [0.0001, 0.001, 0.01, 0.1]\n",
    "\n",
    "\n",
    "\n",
    "# kernel = 'rbf'\n",
    "opt_rbf = []\n",
    "n_simul = len(nu_vector)*len(gamma_vector)\n",
    "count = 0\n",
    "for i in range(len(nu_vector)):\n",
    "    nu = nu_vector[i]\n",
    "    for j in range(len(gamma_vector)):\n",
    "        count += 1\n",
    "        if count % 10 == 0:\n",
    "            print('# simulations done ' + str(count) + '/' + str(n_simul))\n",
    "        gamma = gamma_vector[j]\n",
    "        MSE, VarMSE, missclass = mySVC_Nu(nu=nu, kernel = 'rbf', gamma=gamma, degree=0)\n",
    "        if test_size*MSE/test_size < 0.06 and test_size*VarMSE/test_size < 0.005:\n",
    "            opt_rbf.append([i,j])\n",
    "\n",
    "print('candidate indices for optimal distributions')                \n",
    "print(opt_rbf)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average # misclassified samples from 15 samples: 7.03761904762 +- 0.127499517658 with gamma = 0.0001and nu = 0.1\n",
      "Average # misclassified samples from 15 samples: 7.77630952381 +- 0.0249379755795 with gamma = 0.001and nu = 0.1\n",
      "Average # misclassified samples from 15 samples: 7.77630952381 +- 0.0249379755795 with gamma = 0.01and nu = 0.1\n",
      "Average # misclassified samples from 15 samples: 7.77630952381 +- 0.0249379755795 with gamma = 0.1and nu = 0.1\n",
      "Average # misclassified samples from 15 samples: 6.99261904762 +- 0.119856587502 with gamma = 0.0001and nu = 0.15\n",
      "Average # misclassified samples from 15 samples: 7.77630952381 +- 0.0249379755795 with gamma = 0.001and nu = 0.15\n",
      "Average # misclassified samples from 15 samples: 7.77630952381 +- 0.0249379755795 with gamma = 0.01and nu = 0.15\n",
      "Average # misclassified samples from 15 samples: 7.77630952381 +- 0.0249379755795 with gamma = 0.1and nu = 0.15\n",
      "Average # misclassified samples from 15 samples: 6.99654761905 +- 0.110519210632 with gamma = 0.0001and nu = 0.2\n",
      "Average # misclassified samples from 15 samples: 7.77630952381 +- 0.0249379755795 with gamma = 0.001and nu = 0.2\n",
      "Average # misclassified samples from 15 samples: 7.77630952381 +- 0.0249379755795 with gamma = 0.01and nu = 0.2\n",
      "Average # misclassified samples from 15 samples: 7.77630952381 +- 0.0249379755795 with gamma = 0.1and nu = 0.2\n",
      "Average # misclassified samples from 15 samples: 6.98047619048 +- 0.107051026839 with gamma = 0.0001and nu = 0.25\n",
      "Average # misclassified samples from 15 samples: 7.77630952381 +- 0.0249379755795 with gamma = 0.001and nu = 0.25\n",
      "Average # misclassified samples from 15 samples: 7.77630952381 +- 0.0249379755795 with gamma = 0.01and nu = 0.25\n",
      "Average # misclassified samples from 15 samples: 7.77630952381 +- 0.0249379755795 with gamma = 0.1and nu = 0.25\n",
      "Average # misclassified samples from 15 samples: 7.00416666667 +- 0.10984129916 with gamma = 0.0001and nu = 0.3\n",
      "Average # misclassified samples from 15 samples: 7.77630952381 +- 0.0249379755795 with gamma = 0.001and nu = 0.3\n",
      "Average # misclassified samples from 15 samples: 7.77630952381 +- 0.0249379755795 with gamma = 0.01and nu = 0.3\n",
      "Average # misclassified samples from 15 samples: 7.77630952381 +- 0.0249379755795 with gamma = 0.1and nu = 0.3\n",
      "Average # misclassified samples from 15 samples: 7.15333333333 +- 0.112571240931 with gamma = 0.0001and nu = 0.35\n",
      "Average # misclassified samples from 15 samples: 7.77630952381 +- 0.0249379755795 with gamma = 0.001and nu = 0.35\n",
      "Average # misclassified samples from 15 samples: 7.77630952381 +- 0.0249379755795 with gamma = 0.01and nu = 0.35\n",
      "Average # misclassified samples from 15 samples: 7.77630952381 +- 0.0249379755795 with gamma = 0.1and nu = 0.35\n",
      "Average # misclassified samples from 15 samples: 7.03678571429 +- 0.100311118942 with gamma = 0.0001and nu = 0.4\n",
      "Average # misclassified samples from 15 samples: 7.77630952381 +- 0.0249379755795 with gamma = 0.001and nu = 0.4\n",
      "Average # misclassified samples from 15 samples: 7.77630952381 +- 0.0249379755795 with gamma = 0.01and nu = 0.4\n",
      "Average # misclassified samples from 15 samples: 7.77630952381 +- 0.0249379755795 with gamma = 0.1and nu = 0.4\n"
     ]
    }
   ],
   "source": [
    "axes_vector = []\n",
    "for i in range(len(opt_rbf)):\n",
    "    nu = nu_vector[opt_rbf[i][0]]\n",
    "    gamma = gamma_vector[opt_rbf[i][1]]\n",
    "#     degree = degree_vector[opt_rbf[i][2]]\n",
    "    MSE, VarMSE, missclass = mySVC_Nu(nu=nu, kernel = 'sigmoid', gamma=gamma, degree=0)\n",
    "    axes_vector.append(missclass)\n",
    "    print(r'Average # misclassified samples from ' + str(test_size) + r' samples: ' + \n",
    "              str(test_size*MSE) + r' +- ' + str(test_size*VarMSE) +\\\n",
    "          r' with gamma = ' + str(gamma) +  r'and nu = ' + str(nu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kernel = 'sigmoid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of simulations to be done 135\n",
      "# simulations done 20/135\n",
      "# simulations done 40/135\n",
      "# simulations done 60/135\n",
      "# simulations done 80/135\n",
      "# simulations done 100/135\n",
      "# simulations done 120/135\n",
      "candidate indices for optimal distributions\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "nu_vector = [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6]\n",
    "gamma_vector = [0.00001, 0.0001, 0.001]\n",
    "degree_vector = [2,3,4]\n",
    "\n",
    "# counting how many simulations to be done\n",
    "n_simul_sigm = 0\n",
    "for k in range(len(degree_vector)):\n",
    "    degree = degree_vector[k]\n",
    "    for j in range(len(gamma_vector)):\n",
    "        gamma = gamma_vector[j]\n",
    "        for i in range(len(nu_vector)):\n",
    "            n_simul_sigm += 1\n",
    "\n",
    "print('number of simulations to be done ' + str(n_simul_sigm))\n",
    "\n",
    "\n",
    "# kernel = 'poly'\n",
    "opt_sigm = []\n",
    "count = 0\n",
    "for k in range(len(degree_vector)):\n",
    "    degree = degree_vector[k]\n",
    "    for j in range(len(gamma_vector)):\n",
    "        gamma = gamma_vector[j]\n",
    "        for i in range(len(nu_vector)):\n",
    "            count +=1\n",
    "            if count % 20 == 0:\n",
    "                print('# simulations done ' + str(count) + '/' + str(n_simul_sigm))\n",
    "            nu = nu_vector[i]\n",
    "            MSE, VarMSE, missclass = mySVC_Nu(nu=nu, kernel = 'sigmoid', gamma=gamma, degree=degree)\n",
    "            if test_size*MSE/test_size < 0.06 and test_size*VarMSE/test_size < 0.005:\n",
    "                opt_sigm.append([i,j,k])\n",
    "\n",
    "print('candidate indices for optimal distributions')                \n",
    "print(opt_sigm)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes_vector = []\n",
    "for i in range(len(opt_sigm)):\n",
    "    nu = nu_vector[opt_sigm[i][0]]\n",
    "    gamma = gamma_vector[opt_sigm[i][1]]\n",
    "    degree = degree_vector[opt_sigm[i][2]]\n",
    "    MSE, VarMSE, missclass = mySVC_Nu(nu, kernel = 'sigmoid', gamma=gamma, degree=degree)\n",
    "    axes_vector.append(missclass)\n",
    "    print(r'Average # misclassified samples from ' + str(test_size) + r' samples: ' + \n",
    "              str(test_size*MSE) + r' +- ' + str(test_size*VarMSE) + r' with gamma = ' + str(gamma) + \n",
    "         r', degree ' + str(degree) + ' and nu = ' + str(nu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kernel = 'poly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of simulations to be done 63\n",
      "# simulations done 20/63\n",
      "# simulations done 40/63\n",
      "# simulations done 60/63\n",
      "\n",
      "candidate indices for optimal distributions\n",
      "[[1, 1, 0], [0, 2, 0], [1, 2, 0], [0, 1, 1], [1, 1, 1], [2, 1, 1], [0, 1, 2], [1, 1, 2], [2, 1, 2]]\n"
     ]
    }
   ],
   "source": [
    "nu_vector = [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6]\n",
    "gamma_vector = [0.00001, 0.0001, 0.001]\n",
    "degree_vector = [2,3,4]\n",
    "\n",
    "# counting how many simulations to be done\n",
    "n_simul_poly = 0\n",
    "for k in range(len(degree_vector)):\n",
    "    degree = degree_vector[k]\n",
    "    for j in range(len(gamma_vector)):\n",
    "        gamma = gamma_vector[j]\n",
    "        if degree >= 2 and gamma >= 0.01: continue\n",
    "        if degree >= 3 and gamma >= 0.001: continue\n",
    "        for i in range(len(nu_vector)):\n",
    "            n_simul_poly += 1\n",
    "\n",
    "print('number of simulations to be done ' + str(n_simul_poly))\n",
    "\n",
    "\n",
    "# kernel = 'poly'\n",
    "opt_poly = []\n",
    "count = 0\n",
    "for k in range(len(degree_vector)):\n",
    "    degree = degree_vector[k]\n",
    "    for j in range(len(gamma_vector)):\n",
    "        gamma = gamma_vector[j]\n",
    "        if degree >= 2 and gamma >= 0.01: continue\n",
    "        if degree >= 3 and gamma >= 0.001: continue\n",
    "        for i in range(len(nu_vector)):\n",
    "            count +=1\n",
    "            if count % 20 == 0:\n",
    "                print('# simulations done ' + str(count) + '/' + str(n_simul_poly))\n",
    "            nu = nu_vector[i]\n",
    "            MSE, VarMSE, missclass = mySVC_Nu(nu=nu, kernel = 'poly', gamma=gamma, degree=degree)\n",
    "            if test_size*MSE/test_size < 0.06 and test_size*VarMSE/test_size < 0.005:\n",
    "                opt_poly.append([i,j,k])\n",
    "\n",
    "\n",
    "                \n",
    "print()                \n",
    "print('candidate indices for optimal distributions')                \n",
    "print(opt_poly)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate once again the candidates for optimum to get the histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average # misclassified samples from 15 samples: 0.649047619048 +- 0.00485906919769 with gamma = 0.0001, degree 2 and nu = 0.15\n",
      "Average # misclassified samples from 15 samples: 0.7075 +- 0.0957512226891 with gamma = 0.001, degree 2 and nu = 0.1\n",
      "Average # misclassified samples from 15 samples: 0.652380952381 +- 0.00484573764997 with gamma = 0.001, degree 2 and nu = 0.15\n",
      "Average # misclassified samples from 15 samples: 0.742976190476 +- 0.00459730232878 with gamma = 0.0001, degree 3 and nu = 0.1\n",
      "Average # misclassified samples from 15 samples: 0.679285714286 +- 0.0048135474855 with gamma = 0.0001, degree 3 and nu = 0.15\n",
      "Average # misclassified samples from 15 samples: 0.897380952381 +- 0.00823627482358 with gamma = 0.0001, degree 3 and nu = 0.2\n",
      "Average # misclassified samples from 15 samples: 0.570595238095 +- 0.00453982989036 with gamma = 0.0001, degree 4 and nu = 0.1\n",
      "Average # misclassified samples from 15 samples: 0.692380952381 +- 0.00471951921687 with gamma = 0.0001, degree 4 and nu = 0.15\n",
      "Average # misclassified samples from 15 samples: 0.872142857143 +- 0.00787231297813 with gamma = 0.0001, degree 4 and nu = 0.2\n"
     ]
    }
   ],
   "source": [
    "axes_vector = []\n",
    "for i in range(len(opt_poly)):\n",
    "    nu = nu_vector[opt_poly[i][0]]\n",
    "    gamma = gamma_vector[opt_poly[i][1]]\n",
    "    degree = degree_vector[opt_poly[i][2]]\n",
    "    MSE, VarMSE, missclass = mySVC_Nu(nu, kernel = 'poly', gamma=gamma, degree=degree)\n",
    "    axes_vector.append(missclass)\n",
    "    print(r'Average # misclassified samples from ' + str(test_size) + r' samples: ' + \n",
    "              str(test_size*MSE) + r' +- ' + str(test_size*VarMSE) + r' with gamma = ' + str(gamma) + \n",
    "         r', degree ' + str(degree) + ' and nu = ' + str(nu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABI8AAAJMCAYAAABzWYYiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11489a160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting for optimum\n",
    "rows = 3\n",
    "columns = 3\n",
    "fig, ax = plt.subplots(rows, columns, figsize=(20,10), sharex='col', sharey='row')\n",
    "plt.rcParams.update({'font.size': 9})\n",
    "\n",
    "for i in range(rows):\n",
    "    for j in range(columns):\n",
    "        ax[i,j].hist(axes_vector[columns*i + j], bins=10)\n",
    "        ax[i,j].set_title('degree = ' + str(degree_vector[opt_poly[columns*i + j][2]]) + ', gamma = ' + str (gamma_vector[opt_poly[j][1]]) \\\n",
    "                        + ' and nu = ' + str(nu_vector[opt_poly[columns*i + j][0]]))\n",
    "        ax[i,j].set_ylim(0,500)\n",
    "        ax[i,j].set_xlim(0,2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C-Support Vector Classification\n",
    "\n",
    "see documentation: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC\n",
    "\n",
    "Same as for Nu-SVC (very little changes). Parameter $\\nu$ becomes the parameter C.\n",
    "\n",
    "YOU CAN USE THE PARAMETERS YOU WANT BUT IT IS VERY UNLIKELY THERE WILL BE A CANDIDATE FOR OPTIMAL DISTRIBUTION. The mean may get low but variance is too large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C-Support Vector Classification\n",
    "def mySVC(C, kernel, gamma, degree):  # changed the name of the function\n",
    "\n",
    "    MSE_svc = 0\n",
    "    VarMSE_svc = 0\n",
    "    missclass = []\n",
    "    for i in range(M):\n",
    "        training_features = training_features_vector[i]\n",
    "        testing_features = testing_features_vector[i]\n",
    "        training_target = training_target_vector[i]\n",
    "        testing_target = testing_target_vector[i]\n",
    "\n",
    "        #Training with Nu-SVC\n",
    "        model = SVC(C=C, kernel=kernel, degree=degree, gamma=gamma)\n",
    "        model.fit(training_features, training_target)\n",
    "\n",
    "        #Comparing prediction with testing values\n",
    "        prediction = model.predict(testing_features)\n",
    "\n",
    "        #Get means and std\n",
    "        MSE = mean_squared_error(prediction, testing_target)\n",
    "        MSE_svc += MSE\n",
    "        VarMSE_svc += MSE*MSE\n",
    "        missclass.append(test_size*mean_squared_error(prediction, testing_target))\n",
    "\n",
    "    MSE_svc /= M\n",
    "    VarMSE_svc -= M*MSE_svc**2\n",
    "    VarMSE_svc/=(M-1)\n",
    "    count_svc = test_size*MSE_svc\n",
    "    countVar_svc = test_size*VarMSE_svc\n",
    "    \n",
    "           \n",
    "    return MSE, VarMSE, missclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kernel = 'rbf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_vector = [0.2, 0.4, 0.8, 1, 2, 5, 10]\n",
    "gamma_vector = [0.0001, 0.001, 0.01, 0.1]\n",
    "\n",
    "# kernel = 'rbf'\n",
    "opt_rbf = []\n",
    "n_simul = len(C_vector)*len(gamma_vector)\n",
    "count = 0\n",
    "for i in range(len(C_vector)):\n",
    "    C = C_vector[i]\n",
    "    for j in range(len(gamma_vector)):\n",
    "        count += 1\n",
    "        if count % 10 == 0:\n",
    "            print('# simulations done ' + str(count) + '/' + str(n_simul))\n",
    "        gamma = gamma_vector[j]\n",
    "        MSE, VarMSE, missclass = mySVC(C=C, kernel = 'rbf', gamma=gamma, degree=0) # changed mySVC\n",
    "        if test_size*MSE/test_size < 0.1 and test_size*VarMSE/test_size < 0.05:\n",
    "            opt_rbf.append([i,j])\n",
    "\n",
    "print()\n",
    "if len(opt_rbf) == 0: print('no condidates for optimal distributions')\n",
    "else:        \n",
    "    print('candidate indices for optimal distributions')\n",
    "    print(opt_rbf)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes_vector = []\n",
    "for i in range(len(opt_rbf)):\n",
    "    C = C_vector[opt_rbf[i][0]]\n",
    "    gamma = gamma_vector[opt_rbf[i][1]]\n",
    "    MSE, VarMSE, missclass = mySVC(C, kernel = 'rbf', gamma=gamma, degree=0)\n",
    "    axes_vector.append(missclass)\n",
    "    print(r'Average # misclassified samples from ' + str(test_size) + r' samples: ' + \n",
    "              str(test_size*MSE) + r' +- ' + str(test_size*VarMSE) + r' with gamma = ' + str(gamma) + \n",
    "         r', degree ' + str(degree) + ' and C = ' + str(C))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kernel = 'sigmoid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_vector = [0.2, 0.4, 0.8, 1, 2, 5, 10]\n",
    "gamma_vector = [0.00001, 0.0001, 0.001]\n",
    "degree_vector = [0,1,2,3,4]\n",
    "\n",
    "# counting how many simulations to be done\n",
    "n_simul_sigm = 0\n",
    "for k in range(len(degree_vector)):\n",
    "    degree = degree_vector[k]\n",
    "    for j in range(len(gamma_vector)):\n",
    "        gamma = gamma_vector[j]\n",
    "        for i in range(len(nu_vector)):\n",
    "            n_simul_sigm += 1\n",
    "\n",
    "print('number of simulations to be done ' + str(n_simul_sigm))\n",
    "\n",
    "\n",
    "# kernel = 'sigmoid'\n",
    "opt_sigm = []\n",
    "count = 0\n",
    "for k in range(len(degree_vector)):\n",
    "    degree = degree_vector[k]\n",
    "    for j in range(len(gamma_vector)):\n",
    "        gamma = gamma_vector[j]\n",
    "        for i in range(len(nu_vector)):\n",
    "            count +=1\n",
    "            if count % 20 == 0:\n",
    "                print('# simulations done ' + str(count) + '/' + str(n_simul_sigm))\n",
    "            nu = nu_vector[i]\n",
    "            MSE, VarMSE, missclass = mySVC(C=C, kernel = 'sigmoid', gamma=gamma, degree=degree)\n",
    "            if test_size*MSE/test_size < 0.15 and test_size*VarMSE/test_size < 0.05:\n",
    "                opt_sigm.append([i,j,k])\n",
    "\n",
    "print()\n",
    "if len(opt_sigm == 0: print('no condidates for optimal distributions')\n",
    "else:        \n",
    "    print('candidate indices for optimal distributions')\n",
    "    print(opt_sigm) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kernel = 'poly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_vector = [0.2, 0.4, 0.8, 1, 2, 5, 10]\n",
    "gamma_vector = [0.00001, 0.0001, 0.001]\n",
    "degree_vector = [0,1,2,3,4]\n",
    "\n",
    "# counting how many simulations to be done\n",
    "n_simul_poly = 0\n",
    "for k in range(len(degree_vector)):\n",
    "    degree = degree_vector[k]\n",
    "    for j in range(len(gamma_vector)):\n",
    "        gamma = gamma_vector[j]\n",
    "        if degree >= 2 and gamma >= 0.01: continue\n",
    "        if degree >= 3 and gamma >= 0.001: continue\n",
    "        for i in range(len(nu_vector)):\n",
    "            n_simul_poly += 1\n",
    "\n",
    "print('number of simulations to be done ' + str(n_simul_poly))\n",
    "\n",
    "\n",
    "# kernel = 'poly'\n",
    "opt_poly = []\n",
    "count = 0\n",
    "for k in range(len(degree_vector)):\n",
    "    degree = degree_vector[k]\n",
    "    for j in range(len(gamma_vector)):\n",
    "        gamma = gamma_vector[j]\n",
    "        if degree >= 2 and gamma >= 0.01: continue\n",
    "        if degree >= 3 and gamma >= 0.001: continue\n",
    "        for i in range(len(nu_vector)):\n",
    "            count +=1\n",
    "            if count % 20 == 0:\n",
    "                print('# simulations done ' + str(count) + '/' + str(n_simul_poly))\n",
    "            nu = nu_vector[i]\n",
    "            MSE, VarMSE, missclass = mySVC(C=C, kernel = 'poly', gamma=gamma, degree=degree)\n",
    "            if test_size*MSE/test_size < 0.15 and test_size*VarMSE/test_size < 0.05:\n",
    "                opt_poly.append([i,j,k])\n",
    "\n",
    "\n",
    "print()              \n",
    "if len(opt_rbf) == 0: print('no condidates for optimal distributions')\n",
    "else:        \n",
    "    print('candidate indices for optimal distributions')\n",
    "    print(opt_rbf) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "Simulate once again the candidates for optimum to get the histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes_vector = []\n",
    "for i in range(len(opt_poly)):\n",
    "    nu = nu_vector[opt_poly[i][0]]\n",
    "    gamma = gamma_vector[opt_poly[i][1]]\n",
    "    degree = degree_vector[opt_poly[i][2]]\n",
    "    MSE, VarMSE, missclass = mySVC(C=C, kernel = 'poly', gamma=gamma, degree=degree)\n",
    "    axes_vector.append(missclass)\n",
    "    print(r'Average # misclassified samples from ' + str(test_size) + r' samples: ' + \n",
    "              str(test_size*MSE) + r' +- ' + str(test_size*VarMSE) + r' with gamma = ' + str(gamma) + \n",
    "         r', degree ' + str(degree) + ' and C = ' + str(C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'PTResults_ice.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-4a50b42d5e8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# PT_data = pd.read_excel(\"PTResults_trimmed.xlsx\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# PT_data = pd.read_excel(\"PTResults.xlsx\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mPT_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PTResults_ice.xlsx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheetname, header, skiprows, skip_footer, index_col, names, parse_cols, parse_dates, date_parser, na_values, thousands, convert_float, has_index_names, converters, dtype, true_values, false_values, engine, squeeze, **kwds)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     return io._parse_excel(\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, io, **kwds)\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             raise ValueError('Must explicitly set engine if not passing in'\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_contents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# a ZIP file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'PTResults_ice.xlsx'"
     ]
    }
   ],
   "source": [
    "# Setup pandas options\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:.5f}'.format\n",
    "\n",
    "# Setup numpy options\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "# Get the data\n",
    "# PT_data = pd.read_excel(\"PTResults_trimmed.xlsx\")\n",
    "# PT_data = pd.read_excel(\"PTResults.xlsx\")\n",
    "PT_data = pd.read_excel(\"PTResults_ice.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
