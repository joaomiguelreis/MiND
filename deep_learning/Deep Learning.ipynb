{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class TwoLayerNet(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear modules and assign them as\n",
    "        member variables.\n",
    "        \"\"\"\n",
    "        super(TwoLayerNet, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, 10)\n",
    "        self.linear3 = torch.nn.Linear(10, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Tensor of input data and we must return\n",
    "        a Tensor of output data. We can use Modules defined in the constructor as\n",
    "        well as arbitrary operators on Tensors.\n",
    "        \"\"\"\n",
    "        h_relu = self.linear1(x).clamp(min=0)\n",
    "        h2_relu = self.linear2(h_relu).sigmoid()\n",
    "        y_pred = self.linear3(h2_relu)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# N is size of the training set; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H= 900, 5, 10\n",
    "\n",
    "# Data\n",
    "PT_data = pd.read_excel(\"../Data_Colleff_Entire (1).xlsx\")\n",
    "PT_tensor = torch.tensor(PT_data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.4983e+02, 7.2032e+00, 3.0006e-01, 2.2093e-05, 5.2107e-01],\n",
      "        [2.3684e+02, 1.8626e+00, 4.7278e-01, 2.5871e-05, 8.4452e-01],\n",
      "        [2.4992e+02, 6.8522e+00, 4.0223e-01, 4.5125e-05, 4.2259e-01],\n",
      "        ...,\n",
      "        [2.4429e+02, 5.7239e+00, 4.7114e-01, 4.3566e-05, 9.6588e-01],\n",
      "        [2.6580e+02, 1.5425e+00, 3.9260e-01, 3.1704e-05, 4.5065e-01],\n",
      "        [2.5467e+02, 3.3600e+00, 4.6223e-01, 1.9194e-05, 4.0387e-01]]) tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "175\n",
      "torch.Size([900, 5]) torch.Size([100, 5])\n"
     ]
    }
   ],
   "source": [
    "#Eventually change to batch training and shuffle what is training\n",
    "x_train = PT_tensor[:N,1:6].float()\n",
    "y_train = PT_tensor[:N,6:-1].float()#.view(N,1)\n",
    "\n",
    "print(x_train, y_train)\n",
    "\n",
    "x_test = PT_tensor[N:,1:6].float()\n",
    "y_test = PT_tensor[N:,6:-1].float()#.view(N,1)\n",
    "\n",
    "D_out = len(y_train[0,:])\n",
    "print(D_out)\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.26344534754753113\n",
      "Training accuracy:  120.57555389404297\n",
      "Testing accuracy:  143.0\n",
      "1 0.12692707777023315\n",
      "Training accuracy:  143.3111114501953\n",
      "Testing accuracy:  146.39999389648438\n",
      "2 0.10195139795541763\n",
      "Training accuracy:  146.45333862304688\n",
      "Testing accuracy:  163.25999450683594\n",
      "3 0.04647950828075409\n",
      "Training accuracy:  163.522216796875\n",
      "Testing accuracy:  164.60000610351562\n",
      "4 0.03719524294137955\n",
      "Training accuracy:  164.5288848876953\n",
      "Testing accuracy:  163.82000732421875\n",
      "5 0.03222857788205147\n",
      "Training accuracy:  163.43556213378906\n",
      "Testing accuracy:  162.16000366210938\n",
      "6 0.030198771506547928\n",
      "Training accuracy:  161.4822235107422\n",
      "Testing accuracy:  157.75999450683594\n",
      "7 0.029440298676490784\n",
      "Training accuracy:  157.1266632080078\n",
      "Testing accuracy:  157.75999450683594\n",
      "8 0.028652969747781754\n",
      "Training accuracy:  157.1266632080078\n",
      "Testing accuracy:  156.82000732421875\n",
      "9 0.027175581082701683\n",
      "Training accuracy:  156.5155487060547\n",
      "Testing accuracy:  157.82000732421875\n",
      "10 0.02493392676115036\n",
      "Training accuracy:  157.5155487060547\n",
      "Testing accuracy:  160.63999938964844\n",
      "11 0.022210218012332916\n",
      "Training accuracy:  160.52444458007812\n",
      "Testing accuracy:  165.05999755859375\n",
      "12 0.019405102357268333\n",
      "Training accuracy:  165.14222717285156\n",
      "Testing accuracy:  166.39999389648438\n",
      "13 0.016889218240976334\n",
      "Training accuracy:  166.5111083984375\n",
      "Testing accuracy:  167.0\n",
      "14 0.01491490937769413\n",
      "Training accuracy:  167.2822265625\n",
      "Testing accuracy:  167.1199951171875\n",
      "15 0.013565354980528355\n",
      "Training accuracy:  167.57110595703125\n",
      "Testing accuracy:  167.66000366210938\n",
      "16 0.012762883678078651\n",
      "Training accuracy:  167.84889221191406\n",
      "Testing accuracy:  167.44000244140625\n",
      "17 0.012327361851930618\n",
      "Training accuracy:  167.7822265625\n",
      "Testing accuracy:  166.6999969482422\n",
      "18 0.012041965499520302\n",
      "Training accuracy:  166.94444274902344\n",
      "Testing accuracy:  166.5800018310547\n",
      "19 0.011712535284459591\n",
      "Training accuracy:  166.8000030517578\n",
      "Testing accuracy:  166.5800018310547\n",
      "20 0.011222140863537788\n",
      "Training accuracy:  166.8000030517578\n",
      "Testing accuracy:  166.66000366210938\n",
      "21 0.010560080409049988\n",
      "Training accuracy:  166.6911163330078\n",
      "Testing accuracy:  166.36000061035156\n",
      "22 0.009807424619793892\n",
      "Training accuracy:  166.05332946777344\n",
      "Testing accuracy:  167.17999267578125\n",
      "23 0.0090869115665555\n",
      "Training accuracy:  166.94444274902344\n",
      "Testing accuracy:  167.67999267578125\n",
      "24 0.008500671945512295\n",
      "Training accuracy:  167.3844451904297\n",
      "Testing accuracy:  167.55999755859375\n",
      "25 0.008083933033049107\n",
      "Training accuracy:  167.46888732910156\n",
      "Testing accuracy:  166.0399932861328\n",
      "26 0.0077977473847568035\n",
      "Training accuracy:  165.7933349609375\n",
      "Testing accuracy:  166.8000030517578\n",
      "27 0.007562616840004921\n",
      "Training accuracy:  166.6266632080078\n",
      "Testing accuracy:  166.86000061035156\n",
      "28 0.0073081012815237045\n",
      "Training accuracy:  166.80221557617188\n",
      "Testing accuracy:  167.82000732421875\n",
      "29 0.007008122280240059\n",
      "Training accuracy:  167.7822265625\n",
      "Testing accuracy:  169.1199951171875\n",
      "30 0.006687108892947435\n",
      "Training accuracy:  168.93333435058594\n",
      "Testing accuracy:  169.1199951171875\n",
      "31 0.006398837547749281\n",
      "Training accuracy:  168.93333435058594\n",
      "Testing accuracy:  168.97999572753906\n",
      "32 0.006190220359712839\n",
      "Training accuracy:  168.86666870117188\n",
      "Testing accuracy:  167.94000244140625\n",
      "33 0.006069560535252094\n",
      "Training accuracy:  167.90444946289062\n",
      "Testing accuracy:  167.60000610351562\n",
      "34 0.005999688059091568\n",
      "Training accuracy:  167.52444458007812\n",
      "Testing accuracy:  168.0800018310547\n",
      "35 0.0059231724590063095\n",
      "Training accuracy:  168.2111053466797\n",
      "Testing accuracy:  167.6999969482422\n",
      "36 0.0058023035526275635\n",
      "Training accuracy:  167.91555786132812\n",
      "Testing accuracy:  167.22000122070312\n",
      "37 0.005641405005007982\n",
      "Training accuracy:  167.37777709960938\n",
      "Testing accuracy:  168.0800018310547\n",
      "38 0.0054744938388466835\n",
      "Training accuracy:  167.95333862304688\n",
      "Testing accuracy:  168.16000366210938\n",
      "39 0.005334218963980675\n",
      "Training accuracy:  168.01333618164062\n",
      "Testing accuracy:  168.0800018310547\n",
      "40 0.005231625400483608\n",
      "Training accuracy:  168.09555053710938\n",
      "Testing accuracy:  167.83999633789062\n",
      "41 0.005158585961908102\n",
      "Training accuracy:  167.9711151123047\n",
      "Testing accuracy:  167.83999633789062\n",
      "42 0.005101374816149473\n",
      "Training accuracy:  167.9711151123047\n",
      "Testing accuracy:  168.1999969482422\n",
      "43 0.005050405859947205\n",
      "Training accuracy:  168.3000030517578\n",
      "Testing accuracy:  168.25999450683594\n",
      "44 0.005002045072615147\n",
      "Training accuracy:  168.26889038085938\n",
      "Testing accuracy:  169.1199951171875\n",
      "45 0.004955564625561237\n",
      "Training accuracy:  168.93333435058594\n",
      "Testing accuracy:  169.1199951171875\n",
      "46 0.004909398965537548\n",
      "Training accuracy:  168.93333435058594\n",
      "Testing accuracy:  169.1199951171875\n",
      "47 0.004860929679125547\n",
      "Training accuracy:  168.93333435058594\n",
      "Testing accuracy:  169.1199951171875\n",
      "48 0.004810498096048832\n",
      "Training accuracy:  168.93333435058594\n",
      "Testing accuracy:  169.36000061035156\n",
      "49 0.0047638798132538795\n",
      "Training accuracy:  169.0577850341797\n",
      "Testing accuracy:  169.22000122070312\n",
      "50 0.004728037863969803\n",
      "Training accuracy:  168.99110412597656\n",
      "Testing accuracy:  169.22000122070312\n",
      "51 0.004704266786575317\n",
      "Training accuracy:  168.99110412597656\n",
      "Testing accuracy:  169.22000122070312\n",
      "52 0.004686953034251928\n",
      "Training accuracy:  168.99110412597656\n",
      "Testing accuracy:  169.10000610351562\n",
      "53 0.004668611101806164\n",
      "Training accuracy:  168.84666442871094\n",
      "Testing accuracy:  169.10000610351562\n",
      "54 0.004644947126507759\n",
      "Training accuracy:  168.84666442871094\n",
      "Testing accuracy:  169.24000549316406\n",
      "55 0.004616493824869394\n",
      "Training accuracy:  168.913330078125\n",
      "Testing accuracy:  169.05999755859375\n",
      "56 0.004587967414408922\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "57 0.004565891344100237\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  168.63999938964844\n",
      "58 0.004554339684545994\n",
      "Training accuracy:  168.6022186279297\n",
      "Testing accuracy:  168.63999938964844\n",
      "59 0.004551501478999853\n",
      "Training accuracy:  168.6022186279297\n",
      "Testing accuracy:  168.63999938964844\n",
      "60 0.00455057667568326\n",
      "Training accuracy:  168.6022186279297\n",
      "Testing accuracy:  169.05999755859375\n",
      "61 0.004544469993561506\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "62 0.0045304251834750175\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.36000061035156\n",
      "63 0.0045114983804523945\n",
      "Training accuracy:  169.0577850341797\n",
      "Testing accuracy:  169.36000061035156\n",
      "64 0.0044942256063222885\n",
      "Training accuracy:  169.0577850341797\n",
      "Testing accuracy:  169.36000061035156\n",
      "65 0.004483988042920828\n",
      "Training accuracy:  169.0577850341797\n",
      "Testing accuracy:  169.36000061035156\n",
      "66 0.004481375217437744\n",
      "Training accuracy:  169.0577850341797\n",
      "Testing accuracy:  169.36000061035156\n",
      "67 0.00448240851983428\n",
      "Training accuracy:  169.0577850341797\n",
      "Testing accuracy:  169.36000061035156\n",
      "68 0.004482137504965067\n",
      "Training accuracy:  169.0577850341797\n",
      "Testing accuracy:  169.1199951171875\n",
      "69 0.00447813281789422\n",
      "Training accuracy:  168.93333435058594\n",
      "Testing accuracy:  169.1199951171875\n",
      "70 0.004471210762858391\n",
      "Training accuracy:  168.93333435058594\n",
      "Testing accuracy:  169.05999755859375\n",
      "71 0.00446377694606781\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "72 0.004457863047719002\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "73 0.0044542113319039345\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "74 0.004452405963093042\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "75 0.004451439715921879\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "76 0.004450264852494001\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.3000030517578\n",
      "77 0.004448196850717068\n",
      "Training accuracy:  169.08888244628906\n",
      "Testing accuracy:  169.3000030517578\n",
      "78 0.004445226863026619\n",
      "Training accuracy:  169.08888244628906\n",
      "Testing accuracy:  169.3000030517578\n",
      "79 0.004442107863724232\n",
      "Training accuracy:  169.08888244628906\n",
      "Testing accuracy:  169.3000030517578\n",
      "80 0.004439876414835453\n",
      "Training accuracy:  169.08888244628906\n",
      "Testing accuracy:  169.3000030517578\n",
      "81 0.004438995849341154\n",
      "Training accuracy:  169.08888244628906\n",
      "Testing accuracy:  169.1199951171875\n",
      "82 0.004438942763954401\n",
      "Training accuracy:  168.93333435058594\n",
      "Testing accuracy:  169.1199951171875\n",
      "83 0.0044386847876012325\n",
      "Training accuracy:  168.93333435058594\n",
      "Testing accuracy:  169.1199951171875\n",
      "84 0.004437525290995836\n",
      "Training accuracy:  168.93333435058594\n",
      "Testing accuracy:  169.1199951171875\n",
      "85 0.004435592330992222\n",
      "Training accuracy:  168.93333435058594\n",
      "Testing accuracy:  169.1199951171875\n",
      "86 0.004433687310665846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  168.93333435058594\n",
      "Testing accuracy:  169.05999755859375\n",
      "87 0.004432599991559982\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "88 0.0044324262998998165\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "89 0.004432556219398975\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "90 0.004432336892932653\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.3000030517578\n",
      "91 0.004431644454598427\n",
      "Training accuracy:  169.08888244628906\n",
      "Testing accuracy:  169.3000030517578\n",
      "92 0.004430826287716627\n",
      "Training accuracy:  169.08888244628906\n",
      "Testing accuracy:  169.3000030517578\n",
      "93 0.004430231638252735\n",
      "Training accuracy:  169.08888244628906\n",
      "Testing accuracy:  169.05999755859375\n",
      "94 0.004429883789271116\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "95 0.004429585300385952\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "96 0.004429229535162449\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "97 0.004428892396390438\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "98 0.004428656306117773\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "99 0.0044285012409091\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "100 0.004428370855748653\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "101 0.004428233951330185\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "102 0.0044280667789280415\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "103 0.004427849315106869\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "104 0.004427604377269745\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "105 0.004427406936883926\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "106 0.004427317995578051\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "107 0.00442731287330389\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "108 0.0044273026287555695\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "109 0.004427224863320589\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "110 0.004427092615514994\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "111 0.0044269682839512825\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "112 0.00442689610645175\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "113 0.004426870029419661\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "114 0.004426853731274605\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "115 0.004426816012710333\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "116 0.004426755476742983\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "117 0.004426696337759495\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "118 0.0044266595505177975\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "119 0.004426644649356604\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "120 0.0044266353361308575\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "121 0.00442661764100194\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "122 0.004426589701324701\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "123 0.004426558036357164\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "124 0.004426531493663788\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "125 0.004426513332873583\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "126 0.004426503553986549\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "127 0.004426497500389814\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "128 0.004426490981131792\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "129 0.004426481202244759\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "130 0.004426470026373863\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "131 0.004426458850502968\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "132 0.0044264476746320724\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "133 0.004426436964422464\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "134 0.004426429979503155\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "135 0.004426427185535431\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "136 0.004426426719874144\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "137 0.004426424857228994\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "138 0.004426419734954834\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "139 0.004426412750035524\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "140 0.004426406696438789\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "141 0.004426402971148491\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "142 0.004426401108503342\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "143 0.004426400177180767\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "144 0.004426398780196905\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "145 0.004426396917551756\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "146 0.004426395520567894\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "147 0.0044263931922614574\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "148 0.004426390863955021\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "149 0.004426388535648584\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "150 0.0044263871386647224\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "151 0.0044263871386647224\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "152 0.0044263871386647224\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "153 0.004426386673003435\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "154 0.004426384810358286\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "155 0.004426383413374424\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "156 0.004426382947713137\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "157 0.004426382482051849\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "158 0.004426382482051849\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "159 0.004426382016390562\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "160 0.0044263810850679874\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "161 0.0044263806194067\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "162 0.0044263806194067\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "163 0.004426380153745413\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "164 0.004426380153745413\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "165 0.0044263796880841255\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "166 0.0044263796880841255\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "167 0.004426379222422838\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "168 0.004426379222422838\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "169 0.004426378756761551\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "170 0.004426378756761551\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "171 0.004426378756761551\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "172 0.004426378756761551\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "173 0.004426378291100264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "174 0.004426378291100264\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "175 0.004426378291100264\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "176 0.004426377825438976\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "177 0.004426377825438976\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "178 0.004426377825438976\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "179 0.004426377825438976\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "180 0.004426377825438976\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "181 0.004426377825438976\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "182 0.004426377825438976\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "183 0.004426377825438976\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "184 0.004426377825438976\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "185 0.004426377825438976\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "186 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "187 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "188 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "189 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "190 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "191 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "192 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "193 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "194 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "195 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "196 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "197 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "198 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "199 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "200 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "201 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "202 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "203 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "204 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "205 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "206 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "207 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "208 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "209 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "210 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "211 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "212 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "213 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "214 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "215 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "216 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "217 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "218 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "219 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "220 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "221 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "222 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "223 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "224 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "225 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "226 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "227 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "228 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "229 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "230 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "231 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "232 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "233 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "234 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "235 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "236 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "237 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "238 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "239 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "240 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "241 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "242 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "243 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "244 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "245 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "246 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "247 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "248 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "249 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "250 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "251 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "252 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "253 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "254 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "255 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "256 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "257 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "258 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "259 0.004426377359777689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "260 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "261 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "262 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "263 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "264 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "265 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "266 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "267 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "268 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "269 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "270 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "271 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "272 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "273 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "274 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "275 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "276 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "277 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "278 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "279 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "280 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "281 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "282 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "283 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "284 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "285 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "286 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "287 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "288 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "289 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "290 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "291 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "292 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "293 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "294 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "295 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "296 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "297 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "298 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "299 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "300 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "301 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "302 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "303 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "304 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "305 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "306 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "307 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "308 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "309 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "310 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "311 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "312 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "313 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "314 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "315 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "316 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "317 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "318 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "319 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "320 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "321 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "322 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "323 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "324 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "325 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "326 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "327 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "328 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "329 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "330 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "331 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "332 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "333 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "334 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "335 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "336 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "337 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "338 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "339 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "340 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "341 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "342 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "343 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "344 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "345 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "346 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "347 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy:  169.05999755859375\n",
      "348 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "349 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "350 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "351 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "352 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "353 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "354 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "355 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "356 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "357 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "358 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "359 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "360 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "361 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "362 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "363 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "364 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "365 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "366 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "367 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "368 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "369 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "370 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "371 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "372 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "373 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "374 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "375 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "376 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "377 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "378 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "379 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "380 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "381 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "382 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "383 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "384 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "385 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "386 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "387 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "388 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "389 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "390 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "391 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "392 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "393 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "394 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "395 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "396 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "397 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "398 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "399 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "400 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "401 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "402 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "403 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "404 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "405 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "406 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "407 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "408 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "409 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "410 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "411 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "412 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "413 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "414 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "415 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "416 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "417 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "418 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "419 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "420 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "421 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "422 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "423 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "424 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "425 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "426 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "427 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "428 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "429 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "430 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "431 0.004426377359777689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "432 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "433 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "434 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "435 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "436 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "437 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "438 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "439 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "440 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "441 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "442 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "443 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "444 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "445 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "446 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "447 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "448 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "449 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "450 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "451 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "452 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "453 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "454 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "455 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "456 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "457 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "458 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "459 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "460 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "461 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "462 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "463 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "464 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "465 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "466 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "467 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "468 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "469 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "470 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "471 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "472 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "473 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "474 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "475 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "476 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "477 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "478 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "479 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "480 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "481 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "482 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "483 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "484 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "485 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "486 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "487 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "488 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "489 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "490 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "491 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "492 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "493 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "494 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "495 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "496 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "497 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "498 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n",
      "499 0.004426377359777689\n",
      "Training accuracy:  168.96444702148438\n",
      "Testing accuracy:  169.05999755859375\n"
     ]
    }
   ],
   "source": [
    "# Construct our model by instantiating the class defined above\n",
    "model = TwoLayerNet(D_in, H, D_out)\n",
    "\n",
    "# Construct our loss function and an Optimizer. The call to model.parameters()\n",
    "# in the SGD constructor will contain the learnable parameters of the two\n",
    "# nn.Linear modules which are members of the model.\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-1)\n",
    "for t in range(500):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = model(x_train)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    print(t, loss.item())\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Test accuracy \n",
    "    correct_train = (y_pred.round()==y_train.round()).sum()\n",
    "    acc_train = correct_train.float()/y_train.shape[0]\n",
    "\n",
    "    y_hat = model(x_test)\n",
    "    correct_test = (y_hat.round()==y_test.round()).sum()\n",
    "    acc_test = correct_test.float()/y_test.shape[0]\n",
    "\n",
    "    print('Training accuracy: ', acc_train.item())\n",
    "    print('Testing accuracy: ', acc_test.item())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
