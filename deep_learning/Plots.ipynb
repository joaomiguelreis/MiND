{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from IPython.utils import io\n",
    "from skorch import NeuralNetClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet(torch.nn.Module):\n",
    "    def __init__(self, D_in=5, H=10, D_out=2):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear modules and assign them as\n",
    "        member variables.\n",
    "        \"\"\"\n",
    "        super(TwoLayerNet, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, 10)\n",
    "        self.linear3 = torch.nn.Linear(10, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Tensor of input data and we must return\n",
    "        a Tensor of output data. We can use Modules defined in the constructor as\n",
    "        well as arbitrary operators on Tensors.\n",
    "        \"\"\"\n",
    "        h_relu = self.linear1(x).clamp(min=0)\n",
    "        h2_relu = self.linear2(h_relu).sigmoid()\n",
    "        y_pred = self.linear3(h2_relu)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the net to work with skorch\n",
    "net = NeuralNetClassifier(\n",
    "    TwoLayerNet,\n",
    "    max_epochs=100,\n",
    "    lr=0.01,\n",
    "    criterion = torch.nn.CrossEntropyLoss,\n",
    "    optimizer = torch.optim.Adam,\n",
    "    # Shuffle training data on each epoch\n",
    "    iterator_train__shuffle=True,\n",
    "    callbacks = []\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset with label being one abcsissa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([    'Temperture[K]',            'AoA[o]',              'Mach',\n",
      "                'MVD[mum]',        'rho[kg/m3]',                   0,\n",
      "       0.00847867126218693, 0.01444256487321753, 0.02069919709045778,\n",
      "       0.02724956034185687,\n",
      "       ...\n",
      "        0.9365419465310392,  0.9444633406916711,  0.9521319546962828,\n",
      "        0.9595663922510524,  0.9666372639509644,  0.9733152944189551,\n",
      "        0.9796956385260924,  0.9857709249503196,   0.991539343140028,\n",
      "        0.9971741078954962],\n",
      "      dtype='object', length=181)\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "PT_data_complete = pd.read_excel(\"../PTResults-1000.xlsx\")\n",
    "# clean up\n",
    "PT_data_complete = PT_data_complete.drop(columns = 'Unnamed: 0')\n",
    "print(PT_data_complete.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Temperture[K]    AoA[o]      Mach  MVD[mum]  rho[kg/m3]  label\n",
      "0       249.830880  7.203245  0.300057  0.000022    0.521074      1\n",
      "1       236.843544  1.862602  0.472780  0.000026    0.844524      1\n",
      "2       249.917781  6.852195  0.402226  0.000045    0.422595      1\n",
      "3       259.968700  4.173048  0.579345  0.000016    0.563434      1\n",
      "4       265.179783  9.682616  0.456712  0.000038    1.123021      1\n",
      "5       268.934267  0.850442  0.319527  0.000017    1.124468      0\n",
      "6       237.083873  4.211076  0.778945  0.000031    0.970799      1\n",
      "7       245.770625  6.865009  0.717313  0.000011    1.018869      0\n",
      "8       272.704444  7.481657  0.440222  0.000042    0.485161      1\n",
      "9       251.065741  9.085955  0.446807  0.000022    0.507274      1\n",
      "10      233.924678  6.788355  0.405814  0.000021    0.805548      1\n",
      "11      235.284502  5.741176  0.373364  0.000034    0.977301      1\n",
      "12      237.243377  4.140560  0.647200  0.000027    0.441212      1\n",
      "13      254.585856  6.637946  0.557445  0.000048    0.883908      1\n",
      "14      269.286077  1.374747  0.369638  0.000042    0.728083      1\n",
      "15      239.764168  9.275086  0.473883  0.000040    0.998948      1\n",
      "16      268.482244  6.236722  0.675471  0.000024    0.622691      1\n",
      "17      268.985449  4.280912  0.782420  0.000037    0.912899      1\n",
      "18      237.739839  9.494893  0.524956  0.000033    0.736713      1\n",
      "19      242.631079  9.033795  0.586840  0.000010    0.909145      1\n",
      "20      246.215796  5.270581  0.742971  0.000024    1.149541      1\n",
      "21      258.084405  0.158212  0.764719  0.000038    1.222791      0\n",
      "22      240.043620  1.371357  0.766298  0.000038    0.454450      0\n",
      "23      263.368522  7.538762  0.761512  0.000038    0.502524      1\n",
      "24      233.945205  0.262110  0.314153  0.000020    1.109523      0\n",
      "25      254.703243  5.528220  0.721015  0.000015    0.630327      0\n",
      "26      256.580371  9.695957  0.580515  0.000011    1.060522      1\n",
      "27      242.468971  8.071052  0.493930  0.000045    1.016375      1\n",
      "28      255.399609  1.364552  0.329959  0.000015    0.436755      0\n",
      "29      237.449765  2.257093  0.656494  0.000032    0.410359      1\n",
      "..             ...       ...       ...       ...         ...    ...\n",
      "970     256.334572  0.490975  0.526431  0.000016    1.004580      0\n",
      "971     247.044107  2.011776  0.721394  0.000043    0.683509      1\n",
      "972     249.294912  0.605998  0.389442  0.000039    0.867058      1\n",
      "973     266.079479  5.011501  0.683931  0.000030    0.868657      1\n",
      "974     240.534719  5.444010  0.400517  0.000032    0.516689      1\n",
      "975     240.590400  7.647840  0.335443  0.000025    1.124249      1\n",
      "976     237.323496  3.591532  0.356980  0.000045    0.504146      1\n",
      "977     243.332220  4.219064  0.632628  0.000024    0.576139      1\n",
      "978     248.085404  5.710246  0.795376  0.000023    0.698818      1\n",
      "979     261.399410  2.989357  0.474850  0.000050    0.898521      1\n",
      "980     266.302432  0.316657  0.372745  0.000039    0.845289      1\n",
      "981     272.960580  4.956297  0.492052  0.000018    0.886887      1\n",
      "982     263.815007  9.244392  0.368813  0.000010    0.794317      1\n",
      "983     240.467903  6.103386  0.610135  0.000026    0.958694      1\n",
      "984     241.136823  8.085820  0.325170  0.000017    1.208997      1\n",
      "985     269.165087  9.397290  0.754222  0.000028    1.174513      1\n",
      "986     242.646539  0.495143  0.578632  0.000023    0.838964      0\n",
      "987     252.014343  4.831324  0.585039  0.000047    0.594859      1\n",
      "988     268.193206  7.338354  0.339605  0.000043    0.728056      1\n",
      "989     246.579524  0.003930  0.422903  0.000038    1.102217      0\n",
      "990     242.791979  3.709398  0.375212  0.000042    0.991545      1\n",
      "991     261.169127  6.788545  0.746023  0.000045    0.915928      1\n",
      "992     244.701135  4.031028  0.314479  0.000047    0.967144      1\n",
      "993     269.476833  3.020871  0.772413  0.000045    1.130961      1\n",
      "994     233.155653  3.772402  0.361163  0.000047    0.823808      1\n",
      "995     252.723457  4.869212  0.585146  0.000032    1.156616      1\n",
      "996     268.525382  7.837193  0.461364  0.000041    0.519778      1\n",
      "997     267.559048  7.729997  0.687984  0.000031    0.771403      1\n",
      "998     242.215260  8.086782  0.782965  0.000032    1.144321      1\n",
      "999     244.444018  5.177553  0.464081  0.000050    0.606511      1\n",
      "\n",
      "[1000 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "def PT_data_generator(label_col):\n",
    "    '''\n",
    "    Args:\n",
    "        label_col (int, >4, <181): column to be considered the label\n",
    "    '''\n",
    "    # Make sure the argument is correct\n",
    "    assert 4<label_col<181\n",
    "    \n",
    "    # Create the new dataframe\n",
    "    PT_data = PT_data_complete.copy()\n",
    "    \n",
    "    # Create the column with label\n",
    "    col_name = PT_data.columns[label_col]\n",
    "    PT_data['label'] = PT_data[col_name]\n",
    "    \n",
    "    # Delete all not needed columns\n",
    "    PT_data = PT_data.drop(columns = PT_data.columns[5:-1])\n",
    "    return PT_data\n",
    "\n",
    "PT_data = PT_data_generator(132)\n",
    "print(PT_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt the data to fit with skorch functions \n",
    "# can add to the function eventually\n",
    "label_col = 131\n",
    "PT_data = PT_data_generator(131)\n",
    "PT_numpy = PT_data.values\n",
    "X = PT_numpy[:,:-1]\n",
    "y = PT_numpy[:,-1]\n",
    "X = X.astype(np.float32)\n",
    "y = y.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "precision_mean = [] \n",
    "precision_std = []\n",
    "recall_mean = [] \n",
    "recall_std = []\n",
    "for i in range(5,181):\n",
    "    print(i)\n",
    "    with io.capture_output() as captured:\n",
    "        precision = cross_val_score(net, X, y, scoring = 'precision', cv=10)\n",
    "        recall = cross_val_score(net, X, y, scoring = 'recall', cv=10)\n",
    "    precision_mean.append(precision.mean())\n",
    "    precision_std.append(precision.std())\n",
    "    recall_mean.append(recall.mean())\n",
    "    recall_std.append(recall.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9971741078954962\n"
     ]
    }
   ],
   "source": [
    "##################################\n",
    "\n",
    "## PLOTTING RESULTS ##\n",
    "\n",
    "plt.rc('font',**{'family':'serif','serif':['Palatino']})\n",
    "plt.rc('text', usetex=True)\n",
    "\n",
    "#plt.plot(abscissa, prec_error_3,color='green',label='Tree depth 3')\n",
    "#plt.plot(abscissa, prec_error_6,color='green',label='Tree depth 6')\n",
    "plt.plot(abscissa, prec_error_9,color='green',label='Tree depth 9')\n",
    "plt.fill_between(abscissa, prec_error_9-prec_errstd_9, prec_error_9+prec_errstd_9,  # fills area according to standard deviation\n",
    "    alpha=0.5,color='#e0e0e0')\n",
    "\n",
    "plt.xlabel(r'\\textbf{Abscissa}',fontsize=12)\n",
    "plt.ylabel(r'\\textbf{Precision} [\\%]',fontsize=16)\n",
    "plt.ylim(-0.5,105)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.rc('font',**{'family':'serif','serif':['Palatino']})\n",
    "plt.rc('text', usetex=True)\n",
    "\n",
    "#plt.plot(abscissa, rec_error_3,color='green',label='Tree depth 3')\n",
    "#plt.plot(abscissa, rec_error_6,color='green',label='Tree depth 6')\n",
    "plt.plot(abscissa, rec_error_9,color='green',label='Tree depth 9')\n",
    "plt.fill_between(abscissa, rec_error_9-rec_errstd_9, rec_error_9+rec_errstd_9,  # fills area according to standard deviation\n",
    "    alpha=0.5,color='#e0e0e0')\n",
    "\n",
    "plt.xlabel(r'\\textbf{Abscissa}',fontsize=12)\n",
    "plt.ylabel(r'\\textbf{Recall} [\\%]',fontsize=16)\n",
    "plt.ylim(-0.5,105)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data with all values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([900, 6]) torch.Size([174100, 6])\n",
      "torch.Size([900]) torch.Size([174100])\n"
     ]
    }
   ],
   "source": [
    "## Reorganize the data set\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# N is size of the training set; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H= 900, 6, 10\n",
    "\n",
    "# Data\n",
    "PT_data = pd.read_excel(\"../PTResults-1000.xlsx\")\n",
    "ices = np.zeros(175*1000)\n",
    "for i in range(len(PT_data)):\n",
    "    ice = PT_data.loc[i].iloc[7:len(PT_data.columns)]\n",
    "    ices[i*175:(i+1)*175] = ice.values\n",
    "\n",
    "PT_data = PT_data.iloc[np.repeat(np.arange(len(PT_data)), 175)]\n",
    "drop_icol = list(range(6,len(PT_data.columns)))\n",
    "\n",
    "PT_data = PT_data.drop(PT_data.columns[drop_icol],axis=1)\n",
    "PT_data['loc'] = np.array(list(range(175))*1000)\n",
    "PT_data['ice'] = ices\n",
    "PT_numpy = PT_data.values\n",
    "X = PT_numpy[:,:-1]\n",
    "y = PT_numpy[:,-1]\n",
    "X = X.astype(np.float32)\n",
    "y = y.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test number 0]\n",
      "tensor(160776)\n",
      "Training accuracy:  0.9611111283302307\n",
      "Testing accuracy:  0.9234692454338074\n",
      "[Test number 1]\n",
      "tensor(159991)\n",
      "Training accuracy:  0.9611111283302307\n",
      "Testing accuracy:  0.9189603924751282\n",
      "[Test number 2]\n",
      "tensor(159315)\n",
      "Training accuracy:  0.9599999785423279\n",
      "Testing accuracy:  0.9150775671005249\n",
      "[Test number 3]\n",
      "tensor(130356)\n",
      "Training accuracy:  0.8244444727897644\n",
      "Testing accuracy:  0.7487421035766602\n",
      "[Test number 4]\n",
      "tensor(160586)\n",
      "Training accuracy:  0.9622222185134888\n",
      "Testing accuracy:  0.9223779439926147\n",
      "[Test number 5]\n",
      "tensor(160475)\n",
      "Training accuracy:  0.95333331823349\n",
      "Testing accuracy:  0.9217403531074524\n",
      "[Test number 6]\n",
      "tensor(159183)\n",
      "Training accuracy:  0.9633333086967468\n",
      "Testing accuracy:  0.9143193364143372\n",
      "[Test number 7]\n",
      "tensor(160951)\n",
      "Training accuracy:  0.9599999785423279\n",
      "Testing accuracy:  0.9244744181632996\n",
      "[Test number 8]\n",
      "tensor(158990)\n",
      "Training accuracy:  0.9555555582046509\n",
      "Testing accuracy:  0.9132108092308044\n",
      "[Test number 9]\n",
      "tensor(158777)\n",
      "Training accuracy:  0.9611111283302307\n",
      "Testing accuracy:  0.9119873642921448\n"
     ]
    }
   ],
   "source": [
    "precision_mean = [] \n",
    "precision_std = []\n",
    "recall_mean = [] \n",
    "recall_std = []\n",
    "for i in range(5,181):\n",
    "    print(i)\n",
    "    with io.capture_output() as captured:\n",
    "        precision = cross_val_score(net, X, y, scoring = 'precision', cv=10)\n",
    "        recall = cross_val_score(net, X, y, scoring = 'recall', cv=10)\n",
    "    precision_mean.append(precision.mean())\n",
    "    precision_std.append(precision.std())\n",
    "    recall_mean.append(recall.mean())\n",
    "    recall_std.append(recall.std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
