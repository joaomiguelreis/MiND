{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are some experiments with SVM. Here I test the 3 main SVC (Support Vector Classification) algorithms: Linear SVM, Nu-SVM and C-SVM. The N-SVM seems to be the best but we need more experiments.\n",
    "\n",
    "This analysis is very simple. I shuffle my dataset and take $30\\%$ of testing. I do this $M$ times and store each shuffled data set. Then I preform $M$ classifications and take the mean of thhe numer of miss-classified samples and corresponding variance.\n",
    "\n",
    "This is only for a single cell (like Anabel did). I guess we should have to repeat this for all cells in the mesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import display, Math #\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup pandas options\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:.1f}'.format\n",
    "\n",
    "# Setup numpy options\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "# Get the data\n",
    "PT_data = pd.read_excel(\"PTResults_trimmed.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can change the number of shuffles and test size. This will store the training and testing features and targets to be used for any algorithms you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Temperture[K]  AoA[o]  Mach  MVD[mum]  rho[kg/m3]\n",
      "count           70.0    70.0  70.0      70.0        70.0\n",
      "mean           253.2     5.7   0.6       0.0         0.9\n",
      "std             11.7     3.0   0.1       0.0         0.2\n",
      "min            233.9     0.1   0.3       0.0         0.4\n",
      "25%            244.1     3.5   0.4       0.0         0.6\n",
      "50%            251.5     6.3   0.6       0.0         0.9\n",
      "75%            263.8     8.1   0.7       0.0         1.1\n",
      "max            272.7     9.9   0.8       0.0         1.2\n"
     ]
    }
   ],
   "source": [
    "## TRAINING SVM  ##\n",
    "\n",
    "target = 0.617035028915481\n",
    "X = PT_data.drop(target, axis=1) # Just preparing the data\n",
    "y = PT_data[target]\n",
    "\n",
    "training_features_vector = []\n",
    "testing_features_vector = []\n",
    "training_target_vector = []\n",
    "testing_target_vector = []\n",
    "\n",
    "M = 1000 # number of shuffles\n",
    "test_size = 30 # number of cells to be tested out of 100\n",
    "\n",
    "#Splitting the data into training and testing and storing to reuze same seeds\n",
    "# for the different algorithms\n",
    "for i in range(M):\n",
    "    \n",
    "    training_features, testing_features, training_target, testing_target = train_test_split(\n",
    "        X, y, test_size=test_size/100, shuffle=True)\n",
    "    #store\n",
    "    training_features_vector.append(training_features)\n",
    "    testing_features_vector.append(testing_features)\n",
    "    training_target_vector.append(training_target)\n",
    "    testing_target_vector.append(testing_target)\n",
    "    \n",
    "print(training_features.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This uses the kernel $K(x,x') := \\langle x, x'\\rangle$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of miss classified cells out of 1000 shuffles: 7.457 +- 0.500038405072\n"
     ]
    }
   ],
   "source": [
    "# Linear Support Vector Classification\n",
    "MSE_linear = 0\n",
    "VarMSE_linear = 0\n",
    "ncells_missclass = []\n",
    "for i in range(M):\n",
    "    training_features = training_features_vector[i]\n",
    "    testing_features = testing_features_vector[i]\n",
    "    training_target = training_target_vector[i]\n",
    "    testing_target = testing_target_vector[i]\n",
    "\n",
    "    #Training with Linear SVC\n",
    "    model = LinearSVC(random_state=0, tol=1e-5)\n",
    "    model.fit(training_features, training_target)\n",
    "\n",
    "    #Comparing prediction with testing values\n",
    "    prediction = model.predict(testing_features)\n",
    "    \n",
    "    #Get means and std\n",
    "    MSE = mean_squared_error(prediction, testing_target)\n",
    "    MSE_linear += MSE\n",
    "    VarMSE_linear += MSE*MSE\n",
    "    ncells_missclass.append(30*mean_squared_error(prediction, testing_target))\n",
    "    \n",
    "MSE_linear /= M\n",
    "VarMSE_linear -= M*MSE_linear**2\n",
    "VarMSE_linear /=(M-1)\n",
    "count_linear = test_size*MSE_linear\n",
    "countstd_linear = test_size*VarMSE_linear\n",
    "print('Average number of miss classified cells out of ' + str(M) + ' shuffles: ' + \n",
    "      str(count_linear) + ' +- ' + str(countstd_linear))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nu-Support Vector Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can use different kernels. I guess we want to try Radial Basis Function and Polynomial kernels. Question is which parameters to try?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nu-Support Vector Classification\n",
    "def mySVC_Nu(nu, kernel, gamma, degree=0):\n",
    "\n",
    "    MSE_Nu = 0\n",
    "    VarMSE_Nu = 0\n",
    "    ncells_missclass = []\n",
    "    for i in range(M):\n",
    "        \n",
    "        training_features = training_features_vector[i]\n",
    "        testing_features = testing_features_vector[i]\n",
    "        training_target = training_target_vector[i]\n",
    "        testing_target = testing_target_vector[i]\n",
    "\n",
    "        #Training with Nu-SVC\n",
    "        model = NuSVC(nu = nu, kernel = kernel, degree=degree, gamma=gamma)\n",
    "            \n",
    "        model.fit(training_features, training_target)\n",
    "\n",
    "        #Comparing prediction with testing values\n",
    "        prediction = model.predict(testing_features)\n",
    "\n",
    "        #Get means and std\n",
    "        MSE = mean_squared_error(prediction, testing_target)\n",
    "        MSE_Nu += MSE\n",
    "        VarMSE_Nu += MSE*MSE\n",
    "        ncells_missclass.append(30*mean_squared_error(prediction, testing_target))\n",
    "\n",
    "    MSE_Nu /= M\n",
    "    VarMSE_Nu -= M*MSE_Nu**2\n",
    "    VarMSE_Nu /=(M-1)\n",
    "    count_Nu = test_size*MSE_Nu\n",
    "    countVar_Nu = test_size*VarMSE_Nu\n",
    "    \n",
    "    print(r'Average # miss classified cells from ' + str(M) + r' samples: ' + \n",
    "              str(count_Nu) + r' +- ' + str(countVar_Nu) + r' with gamma = ' + str(gamma) + \n",
    "         r', degree ' + str(degree) + ' and nu = ' + str(nu))\n",
    "           \n",
    "    return MSE_Nu, VarMSE_Nu, ncells_missclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average # miss classified cells from 1000 samples: 5.701 +- 0.123843810477 with gamma = 0.001, degree 0 and nu = 0.35\n",
      "Average # miss classified cells from 1000 samples: 6.752 +- 0.0977142475809 with gamma = 0.01, degree 0 and nu = 0.35\n",
      "Average # miss classified cells from 1000 samples: 8.529 +- 0.12516379713 with gamma = 0.1, degree 0 and nu = 0.35\n",
      "Average # miss classified cells from 1000 samples: 10.607 +- 0.176528228228 with gamma = 1, degree 0 and nu = 0.35\n",
      "Average # miss classified cells from 1000 samples: 11.187 +- 0.208275975976 with gamma = 5, degree 0 and nu = 0.35\n",
      "Average # miss classified cells from 1000 samples: 12.162 +- 0.177369235903 with gamma = 10, degree 0 and nu = 0.35\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA20AAAJLCAYAAAB0cH5VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11da153c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLOTTING for gamma and nu=0.0001\n",
    "axes_vector = []\n",
    "gamma_vector = [0.001,0.01,0.1,1,5,10]\n",
    "nu = 0.35\n",
    "for gamma in gamma_vector:\n",
    "    MSE_Nu, VarMSE_Nu, ncells_missclass = mySVC_Nu(nu, kernel = 'rbf', gamma=gamma)\n",
    "    axes_vector.append(ncells_missclass)\n",
    "\n",
    "rows = 2\n",
    "columns = 3\n",
    "fig, ax = plt.subplots(2, 3, figsize=(15,10), sharex='col', sharey='row')\n",
    "plt.rcParams.update({'font.size': 8})\n",
    "\n",
    "for i in range(rows):\n",
    "    for j in range(columns):\n",
    "        ax[i,j].hist(axes_vector[3*i+j], bins=10)\n",
    "        ax[i,j].set_title('gamma = ' + str(gamma_vector[3*i+j]) + ' and nu = ' + str(nu))\n",
    "        ax[i,j].set_ylim(0,450)\n",
    "        ax[i,j].set_xlim(0,24)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average # miss classified cells from 1000 samples: 12.5 +- 0.168301634968 with gamma = 0.0001, degree 0 and nu = 0.35\n",
      "Average # miss classified cells from 1000 samples: 6.191 +- 0.230047347347 with gamma = 0.0001, degree 1 and nu = 0.35\n",
      "Average # miss classified cells from 1000 samples: 5.106 +- 0.138363830497 with gamma = 0.0001, degree 2 and nu = 0.35\n",
      "Average # miss classified cells from 1000 samples: 4.818 +- 0.149578778779 with gamma = 0.0001, degree 3 and nu = 0.35\n",
      "Average # miss classified cells from 1000 samples: 4.742 +- 0.15867320654 with gamma = 0.0001, degree 4 and nu = 0.35\n",
      "1000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIUAAADPCAYAAABrwGG0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYIY0hQAAAABm6P8Do8ApWMuarOwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11db8d588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLOTTING for degree\n",
    "axes_vector = []\n",
    "degree_vector = [0,1,2,3,4]\n",
    "nu = 0.35\n",
    "for degree in degree_vector:\n",
    "    MSE_Nu, VarMSE_Nu, ncells_missclass = mySVC_Nu(nu, kernel = 'poly', gamma=0.0001, degree=degree)\n",
    "    axes_vector.append(ncells_missclass)\n",
    "\n",
    "rows = 1\n",
    "columns = 5\n",
    "fig, ax = plt.subplots(rows, columns, figsize=(20,3), sharex='col', sharey='row')\n",
    "plt.rcParams.update({'font.size': 8})\n",
    "\n",
    "\n",
    "for j in range(columns):\n",
    "    ax[j].hist(axes_vector[j], bins=10)\n",
    "    ax[j].set_title('degree = ' + str(degree_vector[j]) + ' and nu = ' + str(nu))\n",
    "    ax[j].set_ylim(0,500)\n",
    "    ax[j].set_xlim(0,50)\n",
    "print(M)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average # miss classified cells from 1000 samples: 15.276 +- 0.452112912913 with gamma = 0.0001, degree 0 and nu = 0.1\n",
      "Average # miss classified cells from 1000 samples: 11.274 +- 0.690988455122 with gamma = 0.001, degree 0 and nu = 0.1\n",
      "Average # miss classified cells from 1000 samples: 7.573 +- 0.191213580247 with gamma = 0.01, degree 0 and nu = 0.1\n",
      "Average # miss classified cells from 1000 samples: 9.202 +- 0.163937137137 with gamma = 0.1, degree 0 and nu = 0.1\n",
      "Average # miss classified cells from 1000 samples: 14.734 +- 0.491599733066 with gamma = 0.0001, degree 0 and nu = 0.15\n",
      "Average # miss classified cells from 1000 samples: 9.371 +- 0.399711678345 with gamma = 0.001, degree 0 and nu = 0.15\n",
      "Average # miss classified cells from 1000 samples: 7.31 +- 0.178174841508 with gamma = 0.01, degree 0 and nu = 0.15\n",
      "Average # miss classified cells from 1000 samples: 9.202 +- 0.162602469136 with gamma = 0.1, degree 0 and nu = 0.15\n",
      "Average # miss classified cells from 1000 samples: 14.042 +- 0.502043243243 with gamma = 0.0001, degree 0 and nu = 0.2\n",
      "Average # miss classified cells from 1000 samples: 7.883 +- 0.261238271605 with gamma = 0.001, degree 0 and nu = 0.2\n",
      "Average # miss classified cells from 1000 samples: 7.191 +- 0.17252315649 with gamma = 0.01, degree 0 and nu = 0.2\n",
      "Average # miss classified cells from 1000 samples: 9.276 +- 0.157618418418 with gamma = 0.1, degree 0 and nu = 0.2\n",
      "Average # miss classified cells from 1000 samples: 13.12 +- 0.579165832499 with gamma = 0.0001, degree 0 and nu = 0.25\n",
      "Average # miss classified cells from 1000 samples: 6.818 +- 0.185881748415 with gamma = 0.001, degree 0 and nu = 0.25\n",
      "Average # miss classified cells from 1000 samples: 7.218 +- 0.161510710711 with gamma = 0.01, degree 0 and nu = 0.25\n",
      "Average # miss classified cells from 1000 samples: 9.138 +- 0.140839372706 with gamma = 0.1, degree 0 and nu = 0.25\n",
      "Average # miss classified cells from 1000 samples: 11.301 +- 0.566046012679 with gamma = 0.0001, degree 0 and nu = 0.3\n",
      "Average # miss classified cells from 1000 samples: 6.033 +- 0.140937971305 with gamma = 0.001, degree 0 and nu = 0.3\n",
      "Average # miss classified cells from 1000 samples: 7.11 +- 0.124454454454 with gamma = 0.01, degree 0 and nu = 0.3\n",
      "Average # miss classified cells from 1000 samples: 8.891 +- 0.136573873874 with gamma = 0.1, degree 0 and nu = 0.3\n",
      "Average # miss classified cells from 1000 samples: 8.898 +- 0.413399933267 with gamma = 0.0001, degree 0 and nu = 0.35\n",
      "Average # miss classified cells from 1000 samples: 5.701 +- 0.123843810477 with gamma = 0.001, degree 0 and nu = 0.35\n",
      "Average # miss classified cells from 1000 samples: 6.752 +- 0.0977142475809 with gamma = 0.01, degree 0 and nu = 0.35\n",
      "Average # miss classified cells from 1000 samples: 8.529 +- 0.12516379713 with gamma = 0.1, degree 0 and nu = 0.35\n",
      "Average # miss classified cells from 1000 samples: 6.727 +- 0.212027727728 with gamma = 0.0001, degree 0 and nu = 0.4\n",
      "Average # miss classified cells from 1000 samples: 5.537 +- 0.106394094094 with gamma = 0.001, degree 0 and nu = 0.4\n",
      "Average # miss classified cells from 1000 samples: 6.197 +- 0.0859589923257 with gamma = 0.01, degree 0 and nu = 0.4\n",
      "Average # miss classified cells from 1000 samples: 8.128 +- 0.1132337671 with gamma = 0.1, degree 0 and nu = 0.4\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "nu_vector = [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]\n",
    "gamma_vector = [0.0001, 0.001, 0.01, 0.1]\n",
    "degree_vector = [0,1,2,3,4]\n",
    "\n",
    "\n",
    "\n",
    "# kernel = 'rbf'\n",
    "opt_rbf = []\n",
    "for i in range(len(nu_vector)):\n",
    "    nu = nu_vector[i]\n",
    "    for j in range(len(gamma_vector)):\n",
    "        gamma = gamma_vector[j]\n",
    "        MSE_Nu, VarMSE_Nu, ncells_missclass = mySVC_Nu(nu=nu, kernel = 'rbf', gamma=gamma, degree=0)\n",
    "        if test_size*MSE_Nu < 5.5:\n",
    "            opt_rbf.append([i,j])\n",
    "\n",
    "                \n",
    "print(opt_rbf)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average # miss classified cells from 1000 samples: 12.5 +- 0.168301634968 with gamma = 0.0001, degree 0 and nu = 0.1\n",
      "Average # miss classified cells from 1000 samples: 12.5 +- 0.168301634968 with gamma = 0.0001, degree 0 and nu = 0.15\n",
      "Average # miss classified cells from 1000 samples: 12.5 +- 0.168301634968 with gamma = 0.0001, degree 0 and nu = 0.2\n",
      "Average # miss classified cells from 1000 samples: 12.5 +- 0.168301634968 with gamma = 0.0001, degree 0 and nu = 0.25\n",
      "Average # miss classified cells from 1000 samples: 12.5 +- 0.168301634968 with gamma = 0.0001, degree 0 and nu = 0.3\n",
      "Average # miss classified cells from 1000 samples: 12.5 +- 0.168301634968 with gamma = 0.0001, degree 0 and nu = 0.35\n",
      "Average # miss classified cells from 1000 samples: 12.5 +- 0.168301634968 with gamma = 0.0001, degree 0 and nu = 0.4\n",
      "Average # miss classified cells from 1000 samples: 12.5 +- 0.168301634968 with gamma = 0.0001, degree 0 and nu = 0.5\n",
      "Average # miss classified cells from 1000 samples: 12.5 +- 0.168301634968 with gamma = 0.0001, degree 0 and nu = 0.6\n",
      "Average # miss classified cells from 1000 samples: 12.5 +- 0.168301634968 with gamma = 0.001, degree 0 and nu = 0.1\n",
      "Average # miss classified cells from 1000 samples: 12.5 +- 0.168301634968 with gamma = 0.001, degree 0 and nu = 0.15\n",
      "Average # miss classified cells from 1000 samples: 12.5 +- 0.168301634968 with gamma = 0.001, degree 0 and nu = 0.2\n",
      "Average # miss classified cells from 1000 samples: 12.5 +- 0.168301634968 with gamma = 0.001, degree 0 and nu = 0.25\n",
      "Average # miss classified cells from 1000 samples: 12.5 +- 0.168301634968 with gamma = 0.001, degree 0 and nu = 0.3\n",
      "Average # miss classified cells from 1000 samples: 12.5 +- 0.168301634968 with gamma = 0.001, degree 0 and nu = 0.35\n",
      "Average # miss classified cells from 1000 samples: 12.5 +- 0.168301634968 with gamma = 0.001, degree 0 and nu = 0.4\n",
      "Average # miss classified cells from 1000 samples: 12.5 +- 0.168301634968 with gamma = 0.001, degree 0 and nu = 0.5\n",
      "Average # miss classified cells from 1000 samples: 12.5 +- 0.168301634968 with gamma = 0.001, degree 0 and nu = 0.6\n",
      "Average # miss classified cells from 1000 samples: 12.5 +- 0.168301634968 with gamma = 0.01, degree 0 and nu = 0.1\n",
      "Average # miss classified cells from 1000 samples: 12.5 +- 0.168301634968 with gamma = 0.01, degree 0 and nu = 0.15\n",
      "Average # miss classified cells from 1000 samples: 12.5 +- 0.168301634968 with gamma = 0.01, degree 0 and nu = 0.2\n",
      "Average # miss classified cells from 1000 samples: 12.5 +- 0.168301634968 with gamma = 0.01, degree 0 and nu = 0.25\n",
      "Average # miss classified cells from 1000 samples: 12.5 +- 0.168301634968 with gamma = 0.01, degree 0 and nu = 0.3\n",
      "Average # miss classified cells from 1000 samples: 12.5 +- 0.168301634968 with gamma = 0.01, degree 0 and nu = 0.35\n",
      "Average # miss classified cells from 1000 samples: 12.5 +- 0.168301634968 with gamma = 0.01, degree 0 and nu = 0.4\n",
      "Average # miss classified cells from 1000 samples: 12.5 +- 0.168301634968 with gamma = 0.01, degree 0 and nu = 0.5\n",
      "Average # miss classified cells from 1000 samples: 12.5 +- 0.168301634968 with gamma = 0.01, degree 0 and nu = 0.6\n",
      "Average # miss classified cells from 1000 samples: 12.5 +- 0.168301634968 with gamma = 0.1, degree 0 and nu = 0.1\n",
      "Average # miss classified cells from 1000 samples: 12.5 +- 0.168301634968 with gamma = 0.1, degree 0 and nu = 0.15\n",
      "Average # miss classified cells from 1000 samples: 12.5 +- 0.168301634968 with gamma = 0.1, degree 0 and nu = 0.2\n",
      "Average # miss classified cells from 1000 samples: 12.5 +- 0.168301634968 with gamma = 0.1, degree 0 and nu = 0.25\n",
      "Average # miss classified cells from 1000 samples: 12.5 +- 0.168301634968 with gamma = 0.1, degree 0 and nu = 0.3\n",
      "Average # miss classified cells from 1000 samples: 12.5 +- 0.168301634968 with gamma = 0.1, degree 0 and nu = 0.35\n",
      "Average # miss classified cells from 1000 samples: 12.5 +- 0.168301634968 with gamma = 0.1, degree 0 and nu = 0.4\n",
      "Average # miss classified cells from 1000 samples: 12.5 +- 0.168301634968 with gamma = 0.1, degree 0 and nu = 0.5\n",
      "Average # miss classified cells from 1000 samples: 12.5 +- 0.168301634968 with gamma = 0.1, degree 0 and nu = 0.6\n",
      "Average # miss classified cells from 1000 samples: 12.858 +- 1.36789576243 with gamma = 0.0001, degree 1 and nu = 0.1\n",
      "Average # miss classified cells from 1000 samples: 11.983 +- 1.40896599933 with gamma = 0.0001, degree 1 and nu = 0.15\n",
      "Average # miss classified cells from 1000 samples: 10.518 +- 1.25431017684 with gamma = 0.0001, degree 1 and nu = 0.2\n",
      "Average # miss classified cells from 1000 samples: 8.99 +- 0.985115115115 with gamma = 0.0001, degree 1 and nu = 0.25\n",
      "Average # miss classified cells from 1000 samples: 7.677 +- 0.736692392392 with gamma = 0.0001, degree 1 and nu = 0.3\n",
      "Average # miss classified cells from 1000 samples: 6.191 +- 0.230047347347 with gamma = 0.0001, degree 1 and nu = 0.35\n",
      "Average # miss classified cells from 1000 samples: 5.635 +- 0.126585752419 with gamma = 0.0001, degree 1 and nu = 0.4\n",
      "Average # miss classified cells from 1000 samples: 5.411 +- 0.103973273273 with gamma = 0.0001, degree 1 and nu = 0.5\n",
      "Average # miss classified cells from 1000 samples: 5.426 +- 0.107057857858 with gamma = 0.0001, degree 1 and nu = 0.6\n",
      "Average # miss classified cells from 1000 samples: 11.485 +- 1.25598181515 with gamma = 0.001, degree 1 and nu = 0.1\n",
      "Average # miss classified cells from 1000 samples: 9.527 +- 1.03828064731 with gamma = 0.001, degree 1 and nu = 0.15\n",
      "Average # miss classified cells from 1000 samples: 7.93 +- 0.747183850517 with gamma = 0.001, degree 1 and nu = 0.2\n",
      "Average # miss classified cells from 1000 samples: 6.622 +- 0.517087620954 with gamma = 0.001, degree 1 and nu = 0.25\n",
      "Average # miss classified cells from 1000 samples: 5.563 +- 0.220221254588 with gamma = 0.001, degree 1 and nu = 0.3\n",
      "Average # miss classified cells from 1000 samples: 5.404 +- 0.17713660327 with gamma = 0.001, degree 1 and nu = 0.35\n",
      "Average # miss classified cells from 1000 samples: 5.328 +- 0.116730597264 with gamma = 0.001, degree 1 and nu = 0.4\n",
      "Average # miss classified cells from 1000 samples: 5.38 +- 0.105291958625 with gamma = 0.001, degree 1 and nu = 0.5\n",
      "Average # miss classified cells from 1000 samples: 5.409 +- 0.107231197865 with gamma = 0.001, degree 1 and nu = 0.6\n",
      "Average # miss classified cells from 1000 samples: 11.867 +- 1.95006042709 with gamma = 0.01, degree 1 and nu = 0.1\n",
      "Average # miss classified cells from 1000 samples: 8.524 +- 1.25456870204 with gamma = 0.01, degree 1 and nu = 0.15\n",
      "Average # miss classified cells from 1000 samples: 6.002 +- 0.469068935602 with gamma = 0.01, degree 1 and nu = 0.2\n",
      "Average # miss classified cells from 1000 samples: 5.047 +- 0.205031398065 with gamma = 0.01, degree 1 and nu = 0.25\n",
      "Average # miss classified cells from 1000 samples: 4.746 +- 0.138788254922 with gamma = 0.01, degree 1 and nu = 0.3\n",
      "Average # miss classified cells from 1000 samples: 5.064 +- 0.137601067734 with gamma = 0.01, degree 1 and nu = 0.35\n",
      "Average # miss classified cells from 1000 samples: 5.367 +- 0.108452152152 with gamma = 0.01, degree 1 and nu = 0.4\n",
      "Average # miss classified cells from 1000 samples: 5.378 +- 0.105409275943 with gamma = 0.01, degree 1 and nu = 0.5\n",
      "Average # miss classified cells from 1000 samples: 5.413 +- 0.107321688355 with gamma = 0.01, degree 1 and nu = 0.6\n",
      "Average # miss classified cells from 1000 samples: 20.222 +- 1.23439159159 with gamma = 0.1, degree 1 and nu = 0.1\n",
      "Average # miss classified cells from 1000 samples: 19.39 +- 1.88348014681 with gamma = 0.1, degree 1 and nu = 0.15\n",
      "Average # miss classified cells from 1000 samples: 15.76 +- 3.07141808475 with gamma = 0.1, degree 1 and nu = 0.2\n",
      "Average # miss classified cells from 1000 samples: 8.491 +- 2.11164227561 with gamma = 0.1, degree 1 and nu = 0.25\n",
      "Average # miss classified cells from 1000 samples: 5.45 +- 0.520637303971 with gamma = 0.1, degree 1 and nu = 0.3\n",
      "Average # miss classified cells from 1000 samples: 5.174 +- 0.131121921922 with gamma = 0.1, degree 1 and nu = 0.35\n",
      "Average # miss classified cells from 1000 samples: 5.379 +- 0.10448311645 with gamma = 0.1, degree 1 and nu = 0.4\n",
      "Average # miss classified cells from 1000 samples: 5.377 +- 0.105801501502 with gamma = 0.1, degree 1 and nu = 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average # miss classified cells from 1000 samples: 5.413 +- 0.107321688355 with gamma = 0.1, degree 1 and nu = 0.6\n",
      "Average # miss classified cells from 1000 samples: 10.851 +- 1.19602265599 with gamma = 0.0001, degree 2 and nu = 0.1\n",
      "Average # miss classified cells from 1000 samples: 8.711 +- 0.861777744411 with gamma = 0.0001, degree 2 and nu = 0.15\n",
      "Average # miss classified cells from 1000 samples: 6.989 +- 0.572935568902 with gamma = 0.0001, degree 2 and nu = 0.2\n",
      "Average # miss classified cells from 1000 samples: 5.716 +- 0.266444577911 with gamma = 0.0001, degree 2 and nu = 0.25\n",
      "Average # miss classified cells from 1000 samples: 5.2 +- 0.184250917584 with gamma = 0.0001, degree 2 and nu = 0.3\n",
      "Average # miss classified cells from 1000 samples: 5.106 +- 0.138363830497 with gamma = 0.0001, degree 2 and nu = 0.35\n",
      "Average # miss classified cells from 1000 samples: 5.322 +- 0.123467334001 with gamma = 0.0001, degree 2 and nu = 0.4\n",
      "Average # miss classified cells from 1000 samples: 5.384 +- 0.10525672339 with gamma = 0.0001, degree 2 and nu = 0.5\n",
      "Average # miss classified cells from 1000 samples: 5.359 +- 0.104842142142 with gamma = 0.0001, degree 2 and nu = 0.6\n",
      "Average # miss classified cells from 1000 samples: 15.329 +- 3.0702288622 with gamma = 0.001, degree 2 and nu = 0.1\n",
      "Average # miss classified cells from 1000 samples: 15.164 +- 3.45262275609 with gamma = 0.001, degree 2 and nu = 0.15\n",
      "Average # miss classified cells from 1000 samples: 10.257 +- 3.09445949283 with gamma = 0.001, degree 2 and nu = 0.2\n",
      "Average # miss classified cells from 1000 samples: 5.997 +- 1.23393363363 with gamma = 0.001, degree 2 and nu = 0.25\n",
      "Average # miss classified cells from 1000 samples: 4.536 +- 0.23285632299 with gamma = 0.001, degree 2 and nu = 0.3\n",
      "Average # miss classified cells from 1000 samples: 5.014 +- 0.145005138472 with gamma = 0.001, degree 2 and nu = 0.35\n",
      "Average # miss classified cells from 1000 samples: 5.364 +- 0.114698164832 with gamma = 0.001, degree 2 and nu = 0.4\n",
      "Average # miss classified cells from 1000 samples: 5.385 +- 0.105731564898 with gamma = 0.001, degree 2 and nu = 0.5\n",
      "Average # miss classified cells from 1000 samples: 5.36 +- 0.104984984985 with gamma = 0.001, degree 2 and nu = 0.6\n",
      "Average # miss classified cells from 1000 samples: 9.725 +- 1.69680930931 with gamma = 0.0001, degree 3 and nu = 0.1\n",
      "Average # miss classified cells from 1000 samples: 6.593 +- 0.762607640974 with gamma = 0.0001, degree 3 and nu = 0.15\n",
      "Average # miss classified cells from 1000 samples: 4.952 +- 0.233022889556 with gamma = 0.0001, degree 3 and nu = 0.2\n",
      "Average # miss classified cells from 1000 samples: 4.292 +- 0.133558091425 with gamma = 0.0001, degree 3 and nu = 0.25\n",
      "Average # miss classified cells from 1000 samples: 4.32 +- 0.138591925259 with gamma = 0.0001, degree 3 and nu = 0.3\n",
      "Average # miss classified cells from 1000 samples: 4.818 +- 0.149578778779 with gamma = 0.0001, degree 3 and nu = 0.35\n",
      "Average # miss classified cells from 1000 samples: 5.309 +- 0.121772405739 with gamma = 0.0001, degree 3 and nu = 0.4\n",
      "Average # miss classified cells from 1000 samples: 5.316 +- 0.103708508509 with gamma = 0.0001, degree 3 and nu = 0.5\n",
      "Average # miss classified cells from 1000 samples: 5.313 +- 0.103204237571 with gamma = 0.0001, degree 3 and nu = 0.6\n",
      "Average # miss classified cells from 1000 samples: 6.518 +- 0.799588788789 with gamma = 0.0001, degree 4 and nu = 0.1\n",
      "Average # miss classified cells from 1000 samples: 5.068 +- 0.320032565899 with gamma = 0.0001, degree 4 and nu = 0.15\n",
      "Average # miss classified cells from 1000 samples: 4.149 +- 0.111004304304 with gamma = 0.0001, degree 4 and nu = 0.2\n",
      "Average # miss classified cells from 1000 samples: 3.917 +- 0.100304004004 with gamma = 0.0001, degree 4 and nu = 0.25\n",
      "Average # miss classified cells from 1000 samples: 4.103 +- 0.141354387721 with gamma = 0.0001, degree 4 and nu = 0.3\n",
      "Average # miss classified cells from 1000 samples: 4.742 +- 0.15867320654 with gamma = 0.0001, degree 4 and nu = 0.35\n",
      "Average # miss classified cells from 1000 samples: 5.264 +- 0.126269736403 with gamma = 0.0001, degree 4 and nu = 0.4\n",
      "Average # miss classified cells from 1000 samples: 5.302 +- 0.106466333 with gamma = 0.0001, degree 4 and nu = 0.5\n",
      "Average # miss classified cells from 1000 samples: 5.316 +- 0.102507307307 with gamma = 0.0001, degree 4 and nu = 0.6\n",
      "[[7, 0], [8, 0], [5, 1], [6, 1], [7, 1], [8, 1], [3, 2], [4, 2], [5, 2], [6, 2], [7, 2], [8, 2], [4, 3], [5, 3], [6, 3], [7, 3], [8, 3], [4, 0], [5, 0], [6, 0], [7, 0], [8, 0], [4, 1], [5, 1], [6, 1], [7, 1], [8, 1], [2, 0], [3, 0], [4, 0], [5, 0], [6, 0], [7, 0], [8, 0], [1, 0], [2, 0], [3, 0], [4, 0], [5, 0], [6, 0], [7, 0], [8, 0]]\n"
     ]
    }
   ],
   "source": [
    "nu_vector = [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.6]\n",
    "gamma_vector = [0.0001, 0.001, 0.01, 0.1]\n",
    "degree_vector = [0,1,2,3,4]\n",
    "\n",
    "\n",
    "\n",
    "# kernel = 'poly'\n",
    "opt_rbf = []\n",
    "for k in range(len(degree_vector)):\n",
    "    degree = degree_vector[k]\n",
    "    for j in range(len(gamma_vector)):\n",
    "        gamma = gamma_vector[j]\n",
    "        if degree >= 2 and gamma >= 0.01: continue\n",
    "        if degree >= 3 and gamma >= 0.001: continue\n",
    "        for i in range(len(nu_vector)):\n",
    "            nu = nu_vector[i]\n",
    "            MSE_Nu, VarMSE_Nu, ncells_missclass = mySVC_Nu(nu=nu, kernel = 'poly', gamma=gamma, degree=degree)\n",
    "            if test_size*MSE_Nu < 4.5:\n",
    "                opt_rbf.append([i,j])\n",
    "\n",
    "                \n",
    "print(opt_rbf)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of miss classified cells out of 1000 samples: 8.046 +- 0.135731865199\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD7CAYAAAB+B7/XAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e14e710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Training with C-Support Vector Classification\n",
    "MSE_svc = 0\n",
    "VarMSE_svc = 0\n",
    "ncells_missclass = []\n",
    "for i in range(M):\n",
    "    training_features = training_features_vector[i]\n",
    "    testing_features = testing_features_vector[i]\n",
    "    training_target = training_target_vector[i]\n",
    "    testing_target = testing_target_vector[i]\n",
    "\n",
    "    #Training with Nu-SVC\n",
    "    model = SVC(gamma='auto')\n",
    "    model.fit(training_features, training_target)\n",
    "    \n",
    "    #Comparing prediction with testing values\n",
    "    prediction = model.predict(testing_features)\n",
    "    \n",
    "    #Get means and std\n",
    "    MSE = mean_squared_error(prediction, testing_target)\n",
    "    MSE_svc += MSE\n",
    "    VarMSE_svc += MSE*MSE\n",
    "    ncells_missclass.append(30*mean_squared_error(prediction, testing_target))\n",
    "    \n",
    "MSE_svc /= M\n",
    "VarMSE_svc -= M*MSE_svc**2\n",
    "VarMSE_svc/=(M-1)\n",
    "count_svc = test_size*MSE_svc\n",
    "countVar_svc = test_size*VarMSE_svc\n",
    "print('Average number of miss classified cells out of ' + str(M) + ' samples: ' + \n",
    "      str(str(count_svc) + ' +- ' + str(countVar_svc)))\n",
    "\n",
    "# histogram\n",
    "fig, axes = plt.subplots(1)\n",
    "axes.hist(ncells_missclass, bins=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
