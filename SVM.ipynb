{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import display, Math #\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, recall_score, precision_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC, OneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup pandas options\n",
    "pd.options.display.max_rows = 5\n",
    "pd.options.display.max_columns = 10\n",
    "pd.options.display.float_format = '{:.3f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## READING DATA ##\n",
    "\n",
    "PT_data = pd.read_excel(\"PTData01.xlsx\")\n",
    "PT_data = shuffle(PT_data)\n",
    "targets = PT_data.iloc[:,5:]\n",
    "targets_headers = np.loadtxt(\"abscissa.txt\")\n",
    "\n",
    "\n",
    "## DISTRIBUTION OF WATER CONTENT\n",
    "Data_Cell = pd.read_excel(\"Data_Colleff_Entire.xlsx\") \n",
    "meanWater = np.zeros(len(targets_headers))\n",
    "for h in range(len(targets_headers)):\n",
    "    meanWater[h] = np.mean(Data_Cell.values[:,h+5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_files(errors, curves_labels, metric, algthm_type, extra_labels=None):\n",
    "    \n",
    "    # write txt files\n",
    "    for i in range(len(errors)):\n",
    "        file_name = (str(algthm_type)+'_gamma_'+str(curves_labels[i])+'_'+\\\n",
    "                 str(metric)+'.txt')\n",
    "        np.savetxt('Data/'+str(file_name), errors[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "#CLASSIFIER\n",
    "##################################\n",
    "\n",
    "\n",
    "## TRAINING THE DECISION TREES ##\n",
    "def my_training(my_data, my_model):\n",
    "    ## SETTING UP VARIABLES ##\n",
    "    abscissa = np.loadtxt(\"abscissa.txt\")\n",
    "    ncells = len(abscissa) # Number of abscissa's points\n",
    "\n",
    "    #PRECISION\n",
    "    prec_mean = np.zeros(ncells)\n",
    "    vector_prec_std = np.zeros(ncells)\n",
    "    error_integral_prec = 0.\n",
    "\n",
    "    #RECALL\n",
    "    rec_mean  = np.zeros(ncells)\n",
    "    vector_rec_std = np.zeros(ncells)\n",
    "    error_integral_rec = 0.\n",
    "    \n",
    "    \n",
    "    for i in range(ncells):\n",
    "        prec_std = 0\n",
    "        rec_std = 0\n",
    "        \n",
    "        if i%20==0: print(str(i)+' of '+str(ncells))\n",
    "\n",
    "        target = my_data.iloc[:,5+i]  # PT_data_1000.iloc[:,5:181]\n",
    "        X = my_data.iloc[:,0:5].values # PT_data_1000.drop(target, axis=1)  # Remove all columns that are target     \n",
    "        y = target.values\n",
    "        \n",
    "        \n",
    "        \n",
    "        kf = KFold(n_splits=10, shuffle=False)\n",
    "        kf.get_n_splits(X)\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            if np.sum(np.asarray(y_train)) == 0 or np.sum(np.asarray(y_train)) == len(y_train):\n",
    "\n",
    "                # if trn_target = [0,0,...,0,0] then metric = 0\n",
    "                if np.sum(np.asarray(y_train)) == 0:\n",
    "\n",
    "                    recall = 0\n",
    "                    precision = 0\n",
    "\n",
    "                # if trn_target = [1,1,...,1,1] then metric = 1\n",
    "                if np.sum(np.asarray(y_train)) == len(y_train):\n",
    "                    recall = 1\n",
    "                    precision = 1\n",
    "\n",
    "            else:\n",
    "\n",
    "                #Fit model\n",
    "                model.fit(X_train, y_train)\n",
    "\n",
    "                #Comparing prediction with testing values\n",
    "                prediction = model.predict(X_test)\n",
    "\n",
    "\n",
    "                # Making predictions on the testing features set with precision metric\n",
    "                precision = precision_score(y_test, prediction)\n",
    "\n",
    "\n",
    "                # Making predictions on the testing features set with recall metric\n",
    "                recall = recall_score(y_test, prediction)\n",
    "                \n",
    "                \n",
    "            \n",
    "            prec_mean[i] += precision\n",
    "            prec_std += precision*precision\n",
    "            \n",
    "            rec_mean[i] += recall\n",
    "            rec_std += recall*recall\n",
    "            \n",
    "            \n",
    "        prec_mean[i] /= 10\n",
    "        prec_std -= 10*prec_mean[i]*prec_mean[i]\n",
    "        prec_std /= 9\n",
    "        vector_prec_std[i] = prec_std\n",
    "        \n",
    "        rec_mean[i] /= 10\n",
    "        rec_std -= 10*rec_mean[i]*rec_mean[i]\n",
    "        rec_std /= 9\n",
    "        vector_rec_std[i] = rec_std\n",
    "        \n",
    "        # computing integral\n",
    "        if i>0:\n",
    "            dx = abscissa[i] - abscissa[i-1]\n",
    "            error_integral_rec += rec_mean[i]*dx\n",
    "            error_integral_prec += prec_mean[i]*dx\n",
    "\n",
    "    rec_mean = rec_mean * 100\n",
    "    vector_rec_std = vector_rec_std * 100\n",
    "    error_integral_rec = error_integral_rec * 100\n",
    "    \n",
    "    prec_mean = prec_mean * 100\n",
    "    vector_prec_std = vector_prec_std * 100\n",
    "    error_integral_prec = error_integral_prec * 100\n",
    "\n",
    "\n",
    "    return rec_mean, prec_mean, error_integral_rec, \\\n",
    "            error_integral_prec, vector_rec_std, vector_prec_std\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[C] 0.001\n",
      "[\\gamma] 0.001\n",
      "0 of 176\n",
      "20 of 176\n",
      "40 of 176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 of 176\n",
      "80 of 176\n",
      "100 of 176\n",
      "120 of 176\n",
      "140 of 176\n",
      "160 of 176\n",
      "[\\gamma] 0.01\n",
      "0 of 176\n",
      "20 of 176\n",
      "40 of 176\n",
      "60 of 176\n",
      "80 of 176\n",
      "100 of 176\n",
      "120 of 176\n",
      "140 of 176\n",
      "160 of 176\n",
      "[\\gamma] 0.1\n",
      "0 of 176\n",
      "20 of 176\n",
      "40 of 176\n",
      "60 of 176\n",
      "80 of 176\n",
      "100 of 176\n",
      "120 of 176\n",
      "140 of 176\n",
      "160 of 176\n",
      "[\\gamma] 1\n",
      "0 of 176\n",
      "20 of 176\n",
      "40 of 176\n",
      "60 of 176\n",
      "80 of 176\n",
      "100 of 176\n",
      "120 of 176\n",
      "140 of 176\n",
      "160 of 176\n",
      "[C] 0.01\n",
      "[\\gamma] 0.001\n",
      "0 of 176\n",
      "20 of 176\n",
      "40 of 176\n",
      "60 of 176\n",
      "80 of 176\n",
      "100 of 176\n",
      "120 of 176\n",
      "140 of 176\n",
      "160 of 176\n",
      "[\\gamma] 0.01\n",
      "0 of 176\n",
      "20 of 176\n",
      "40 of 176\n",
      "60 of 176\n",
      "80 of 176\n",
      "100 of 176\n",
      "120 of 176\n",
      "140 of 176\n",
      "160 of 176\n",
      "[\\gamma] 0.1\n",
      "0 of 176\n",
      "20 of 176\n",
      "40 of 176\n",
      "60 of 176\n",
      "80 of 176\n",
      "100 of 176\n",
      "120 of 176\n",
      "140 of 176\n",
      "160 of 176\n",
      "[\\gamma] 1\n",
      "0 of 176\n",
      "20 of 176\n",
      "40 of 176\n",
      "60 of 176\n",
      "80 of 176\n",
      "100 of 176\n",
      "120 of 176\n",
      "140 of 176\n",
      "160 of 176\n",
      "[C] 0.1\n",
      "[\\gamma] 0.001\n",
      "0 of 176\n",
      "20 of 176\n",
      "40 of 176\n",
      "60 of 176\n",
      "80 of 176\n",
      "100 of 176\n",
      "120 of 176\n",
      "140 of 176\n",
      "160 of 176\n",
      "[\\gamma] 0.01\n",
      "0 of 176\n",
      "20 of 176\n",
      "40 of 176\n",
      "60 of 176\n",
      "80 of 176\n",
      "100 of 176\n",
      "120 of 176\n",
      "140 of 176\n",
      "160 of 176\n",
      "[\\gamma] 0.1\n",
      "0 of 176\n",
      "20 of 176\n",
      "40 of 176\n",
      "60 of 176\n",
      "80 of 176\n",
      "100 of 176\n",
      "120 of 176\n",
      "140 of 176\n",
      "160 of 176\n",
      "[\\gamma] 1\n",
      "0 of 176\n",
      "20 of 176\n",
      "40 of 176\n",
      "60 of 176\n",
      "80 of 176\n",
      "100 of 176\n",
      "120 of 176\n",
      "140 of 176\n",
      "160 of 176\n",
      "[C] 1\n",
      "[\\gamma] 0.001\n",
      "0 of 176\n",
      "20 of 176\n",
      "40 of 176\n",
      "60 of 176\n",
      "80 of 176\n",
      "100 of 176\n",
      "120 of 176\n",
      "140 of 176\n",
      "160 of 176\n",
      "[\\gamma] 0.01\n",
      "0 of 176\n",
      "20 of 176\n",
      "40 of 176\n",
      "60 of 176\n",
      "80 of 176\n",
      "100 of 176\n",
      "120 of 176\n",
      "140 of 176\n",
      "160 of 176\n",
      "[\\gamma] 0.1\n",
      "0 of 176\n",
      "20 of 176\n",
      "40 of 176\n",
      "60 of 176\n",
      "80 of 176\n",
      "100 of 176\n",
      "120 of 176\n",
      "140 of 176\n",
      "160 of 176\n",
      "[\\gamma] 1\n",
      "0 of 176\n",
      "20 of 176\n",
      "40 of 176\n",
      "60 of 176\n",
      "80 of 176\n",
      "100 of 176\n",
      "120 of 176\n",
      "140 of 176\n",
      "160 of 176\n",
      ".    [14.747762131738423, 14.747762131738423, 14.747762131738423, 14.747762131738423]\n",
      ".    [11.864417416921516, 11.864417416921516, 11.864417416921516, 11.864417416921516]\n"
     ]
    }
   ],
   "source": [
    "gamma_vector = [0.001, 0.01, 0.1, 1]\n",
    "C_vector = [0.001, 0.01, 0.1, 1]\n",
    "ngamma = len(gamma_vector)\n",
    "nC = len(C_vector)\n",
    "\n",
    "# builds vector_Precision and vector_Recall\n",
    "vector_Recall = []\n",
    "vector_Precision = []\n",
    "vector_Recall_std = []\n",
    "vector_Precision_std = []\n",
    "degree = 0\n",
    "kernel='poly'\n",
    "for j in range(nC):\n",
    "    vector_integral_rec = []\n",
    "    vector_integral_prec = []\n",
    "    c = C_vector[j]\n",
    "    print(r'[C] ' + str(c))\n",
    "    for i in range(ngamma):\n",
    "        gamma = gamma_vector[i]\n",
    "        label = str(gamma)\n",
    "        print(r'[\\gamma] ' + str(gamma))\n",
    "        model = SVC(C=c, kernel=kernel, degree=degree, gamma=gamma)\n",
    "        Recall, Precision, error_integral_rec, error_integral_prec, \\\n",
    "                    prec_std, rec_std = my_training(PT_data, model)\n",
    "        vector_Recall.append(Recall)\n",
    "        vector_Precision.append(Precision)\n",
    "        vector_Recall_std.append(rec_std)\n",
    "        vector_Precision_std.append(prec_std)\n",
    "        vector_integral_rec.append(error_integral_rec)\n",
    "        vector_integral_prec.append(error_integral_prec)\n",
    "\n",
    "print('.    ' +str(vector_integral_rec))\n",
    "print('.    ' +str(vector_integral_prec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will write the files in .txt so that I don't loose them. See the other notebook for plotting in Data/Plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC_poly_0_c_0.001\n",
      "[C] 0.001\n",
      "['0.001', '0.01', '0.1', '1']\n",
      "SVC_poly_0_c_0.01\n",
      "[C] 0.01\n",
      "['0.001', '0.01', '0.1', '1']\n",
      "SVC_poly_0_c_0.1\n",
      "[C] 0.1\n",
      "['0.001', '0.01', '0.1', '1']\n",
      "SVC_poly_0_c_1\n",
      "[C] 1\n",
      "['0.001', '0.01', '0.1', '1']\n",
      "SVC_poly_0_c_0.001\n",
      "[C] 0.001\n",
      "['0.001', '0.01', '0.1', '1']\n",
      "SVC_poly_0_c_0.01\n",
      "[C] 0.01\n",
      "['0.001', '0.01', '0.1', '1']\n",
      "SVC_poly_0_c_0.1\n",
      "[C] 0.1\n",
      "['0.001', '0.01', '0.1', '1']\n",
      "SVC_poly_0_c_1\n",
      "[C] 1\n",
      "['0.001', '0.01', '0.1', '1']\n"
     ]
    }
   ],
   "source": [
    "# This requires creating a directory with the name 'Plots'\n",
    "ngamma = len(gamma_vector)\n",
    "nC = len(C_vector)\n",
    "\n",
    "errors_vector = [vector_Precision, vector_Recall]\n",
    "errors_metric = ['precision', 'recall']\n",
    "\n",
    "# set of plots 1\n",
    "for m in range(2):\n",
    "    metric = errors_metric[m]\n",
    "    for j in range(nC):\n",
    "        c = C_vector[j]\n",
    "        algthm_type = 'SVC_'+str(kernel)+'_'+str(degree)+'_c_' + str(C_vector[j])\n",
    "        print(algthm_type)\n",
    "        errors = []\n",
    "        curves_labels = []\n",
    "        print(r'[C] ' + str(c))\n",
    "        for i in range(ngamma):\n",
    "            g = gamma_vector[i]\n",
    "            label = str(g)\n",
    "            curves_labels.append(label)\n",
    "            errors.append(errors_vector[m][ngamma*j + i])\n",
    "        print(curves_labels)\n",
    "        write_files(errors, curves_labels, metric, algthm_type)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std_SVC_poly_0_c_0.001\n",
      "[C] 0.001\n",
      "['0.001', '0.01', '0.1', '1']\n",
      "std_SVC_poly_0_c_0.01\n",
      "[C] 0.01\n",
      "['0.001', '0.01', '0.1', '1']\n",
      "std_SVC_poly_0_c_0.1\n",
      "[C] 0.1\n",
      "['0.001', '0.01', '0.1', '1']\n",
      "std_SVC_poly_0_c_1\n",
      "[C] 1\n",
      "['0.001', '0.01', '0.1', '1']\n",
      "std_SVC_poly_0_c_0.001\n",
      "[C] 0.001\n",
      "['0.001', '0.01', '0.1', '1']\n",
      "std_SVC_poly_0_c_0.01\n",
      "[C] 0.01\n",
      "['0.001', '0.01', '0.1', '1']\n",
      "std_SVC_poly_0_c_0.1\n",
      "[C] 0.1\n",
      "['0.001', '0.01', '0.1', '1']\n",
      "std_SVC_poly_0_c_1\n",
      "[C] 1\n",
      "['0.001', '0.01', '0.1', '1']\n"
     ]
    }
   ],
   "source": [
    "# This requires creating a directory with the name 'Plots'\n",
    "ngamma = len(gamma_vector)\n",
    "nC = len(C_vector)\n",
    "\n",
    "errors_vector = [vector_Precision, vector_Recall]\n",
    "std_vector = [vector_Precision_std, vector_Recall_std]\n",
    "\n",
    "errors_metric = ['precision', 'recall']\n",
    "\n",
    "# set of plots 1\n",
    "for m in range(2):\n",
    "    metric = errors_metric[m]\n",
    "    for j in range(nC):\n",
    "        c = C_vector[j]\n",
    "        algthm_type = 'std_SVC_'+str(kernel)+'_'+str(degree)+'_c_' + str(C_vector[j])\n",
    "        print(algthm_type)\n",
    "        stds = []\n",
    "        curves_labels = []\n",
    "        print(r'[C] ' + str(c))\n",
    "        for i in range(ngamma):\n",
    "            g = gamma_vector[i]\n",
    "            label = str(g)\n",
    "            curves_labels.append(label)\n",
    "            stds.append(std_vector[m][ngamma*j + i])\n",
    "        print(curves_labels)\n",
    "        write_files(stds, curves_labels, metric, algthm_type)\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
